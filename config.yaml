training_mode: False
use_gpu: False

checkpoint_load_path: "models/um_run1.pth"
checkpoint_save_path: "models/um_run5.pth"

actor_lr: 0.0001
critic_lr: 0.0003

energy_reward_scale: 10.0
cost_scale: 1.0

entropy_coef: 0.01
gamma: 0.99
lambda_gae: 0.95
clip_epsilon: 0.2
ppo_epochs: 4
batch_size: 1
buffer_size: 4
n_envs: 4
hidden_dim: 256

# Lagrangian PPO settings
lambda_init: 0.0
lambda_lr: 0.05
lambda_max: 100.0
# Target average cost per step (set per-scenario scale). 0 encourages constraint satisfaction.
cost_target: 0.0
# Practical tolerance and early stop
cost_tolerance: 0.1
cost_stop_patience: 10


