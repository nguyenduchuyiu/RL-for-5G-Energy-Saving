{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RL-for-5G-Energy-Saving'...\n"
     ]
    }
   ],
   "source": [
    "!git clone -b lagrangian-ppo --single-branch https://github.com/nguyenduchuyiu/RL-for-5G-Energy-Saving.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RL-for-5G-Energy-Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/dense_urban.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/dense_urban.json\n",
    "{\n",
    "  \"name\": \"Dense Urban\",\n",
    "  \"description\": \"3GPP Dense urban with macro and micro cells\",\n",
    "  \"deploymentScenario\": \"dense_urban\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"two_layer\",\n",
    "  \"isd\": 200,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"Uniform/macro\",\n",
    "  \"ueSpeed\": 3,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 10,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 20,\n",
    "  \"peakHourMultiplier\": 1.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/urban_macro.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/urban_macro.json\n",
    "    {\n",
    "  \"name\": \"3GPP Urban Macro\",\n",
    "  \"description\": \"3GPP Urban macro deployment scenario with large cells and continuous coverage\",\n",
    "  \"deploymentScenario\": \"urban_macro\",\n",
    "  \n",
    "  \"carrierFrequency\": 2e9,\n",
    "  \"systemBandwidth\": 100e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 500,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 30,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 4096,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 25,\n",
    "  \"peakHourMultiplier\": 1.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/high_speed.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/high_speed.json\n",
    "{\n",
    "  \"name\": \"High Speed\",\n",
    "  \"description\": \"3GPP High speed scenario for railway with linear deployment\",\n",
    "  \"deploymentScenario\": \"high_speed\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"linear_railway\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 2,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"100% of users in train\",\n",
    "  \"ueSpeed\": 500,\n",
    "  \"indoorRatio\": 1.0,\n",
    "  \"trainLength\": 200,\n",
    "  \"trackLength\": 10000,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -95,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 30,\n",
    "  \"peakHourMultiplier\": 1.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/rural.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/rural.json\n",
    "{\n",
    "  \"name\": \"3GPP Rural Macro\",\n",
    "  \"description\": \"3GPP Rural deployment scenario with wide area coverage for high speed vehicles\",\n",
    "  \"deploymentScenario\": \"rural\",\n",
    "  \n",
    "  \"carrierFrequency\": 700e6,\n",
    "  \"systemBandwidth\": 20e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 19,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 100,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 120,\n",
    "  \"indoorRatio\": 0.5,\n",
    "  \"outdoorSpeed\": 120,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -115,\n",
    "  \"rsrpTargetThreshold\": -105,\n",
    "  \"rsrpMeasurementThreshold\": -120,\n",
    "  \"dropCallThreshold\": 2,\n",
    "  \"latencyThreshold\": 100,\n",
    "  \"cpuThreshold\": 90,\n",
    "  \"prbThreshold\": 90,\n",
    "  \n",
    "  \"trafficLambda\": 10,\n",
    "  \"peakHourMultiplier\": 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "training_mode: True\n",
    "use_gpu: False\n",
    "\n",
    "checkpoint_load_path: \"models/zero.pth\"\n",
    "checkpoint_save_path: \"models/um_run1.pth\"\n",
    "\n",
    "actor_lr: 0.0001\n",
    "critic_lr: 0.0003\n",
    "\n",
    "energy_reward_scale: 10.0\n",
    "cost_scale: 1.0\n",
    "\n",
    "entropy_coef: 0.01\n",
    "gamma: 0.99\n",
    "lambda_gae: 0.95\n",
    "clip_epsilon: 0.2\n",
    "ppo_epochs: 4\n",
    "batch_size: 1\n",
    "buffer_size: 4\n",
    "n_envs: 4\n",
    "hidden_dim: 256\n",
    "\n",
    "# Lagrangian PPO settings\n",
    "lambda_init: 0.0\n",
    "lambda_lr: 0.05\n",
    "lambda_max: 100.0\n",
    "# Target average cost per step (set per-scenario scale). 0 encourages constraint satisfaction.\n",
    "cost_target: 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huy/anaconda3/envs/mira/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\n",
      "=== Running Benchmark Suite (4 scenarios) ===\n",
      "Scenarios directory: app/train_scenarios/\n",
      "Using 4 parallel environments per scenario\n",
      "Loaded scenarios: ['dense_urban', 'high_speed', 'rural', 'urban_macro']\n",
      "\n",
      "\n",
      "--- Scenario 1/4: dense_urban ---\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Created 4 parallel environments\n",
      "  Scenario: dense_urban\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: Dense Urban\n",
      "Skipping scenario dense_urban: simTime=0\n",
      "Loaded scenario: Dense Urban\n",
      "\n",
      "Results for dense_urban:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 2/4: high_speed ---\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Created 4 parallel environments\n",
      "  Scenario: high_speed\n",
      "  Action dim: 14\n",
      "  Obs dim: 196\n",
      "Loaded scenario: High Speed\n",
      "Skipping scenario high_speed: simTime=0\n",
      "Loaded scenario: High Speed\n",
      "\n",
      "Results for high_speed:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 3/4: rural ---\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: rural\n",
      "  Action dim: 57\n",
      "  Obs dim: 712\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Skipping scenario rural: simTime=0\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "\n",
      "Results for rural:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 4/4: urban_macro ---\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: urban_macro\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "2025-11-04 00:29:33,043 - PPOAgent - INFO - PPO Agent initialized: 21 cells, 300 UEs\n",
      "2025-11-04 00:29:33,043 - PPOAgent - INFO - State dim: 817, Action dim: 100\n",
      "2025-11-04 00:29:33,043 - PPOAgent - INFO - Device: cpu\n",
      "2025-11-04 00:29:33,043 - PPOAgent - INFO - No checkpoint found at models/zero.pth\n",
      "Created 7 sites for urban_macro scenarioCreated 7 sites for urban_macro scenario\n",
      "\n",
      "Configuring cells for urban_macro scenario...Configuring cells for urban_macro scenario...\n",
      "\n",
      "Configured 21 cells for urban_macro scenarioConfigured 21 cells for urban_macro scenario\n",
      "\n",
      "Created 7 sites for urban_macro scenarioCreated 7 sites for urban_macro scenario\n",
      "\n",
      "Configuring cells for urban_macro scenario...Configuring cells for urban_macro scenario...\n",
      "\n",
      "Configured 21 cells for urban_macro scenarioConfigured 21 cells for urban_macro scenario\n",
      "\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "===================Starting scenario===================\n",
      "2025-11-04 00:29:44,338 - PPOAgent - INFO - Starting episode: 1\n",
      "Training with 4 parallel environments...\n",
      "Total steps: 4096\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "2025-11-04 00:29:57,107 - PPOAgent - INFO - Train: J_r=1.0000, J_c=0.0000, Lambda=0.0000, Actor Loss=-0.2560, Critic Loss=0.2976, Cost Critic Loss=2851.2400, Entropy=25.5977\n",
      "2025-11-04 00:29:57,107 - PPOAgent - INFO - Starting episode: 2\n",
      "2025-11-04 00:30:08,587 - PPOAgent - INFO - Train: J_r=-1.0000, J_c=1.5437, Lambda=0.0772, Actor Loss=-1.5966, Critic Loss=0.0000, Cost Critic Loss=0.8155, Entropy=19.7653\n",
      "2025-11-04 00:30:08,587 - PPOAgent - INFO - Starting episode: 3\n",
      "2025-11-04 00:30:20,034 - PPOAgent - INFO - Train: J_r=-12.5351, J_c=1.5648, Lambda=0.1554, Actor Loss=0.6588, Critic Loss=954.0114, Cost Critic Loss=2.5170, Entropy=19.8031\n",
      "2025-11-04 00:30:20,034 - PPOAgent - INFO - Starting episode: 4\n",
      "2025-11-04 00:30:31,561 - PPOAgent - INFO - Train: J_r=18.8726, J_c=1.3361, Lambda=0.2222, Actor Loss=-1.3232, Critic Loss=3194.4683, Cost Critic Loss=0.0017, Entropy=19.9171\n",
      "2025-11-04 00:30:31,561 - PPOAgent - INFO - Starting episode: 5\n",
      "2025-11-04 00:30:42,944 - PPOAgent - INFO - Train: J_r=-2.1761, J_c=1.7469, Lambda=0.3096, Actor Loss=-1.7206, Critic Loss=1179.5891, Cost Critic Loss=0.2856, Entropy=19.9104\n",
      "2025-11-04 00:30:42,945 - PPOAgent - INFO - Starting episode: 6\n",
      "2025-11-04 00:30:54,474 - PPOAgent - INFO - Train: J_r=13.2932, J_c=1.1137, Lambda=0.3653, Actor Loss=-0.9547, Critic Loss=1291.2377, Cost Critic Loss=0.3230, Entropy=20.9470\n",
      "2025-11-04 00:30:54,474 - PPOAgent - INFO - Starting episode: 7\n",
      "2025-11-04 00:31:05,809 - PPOAgent - INFO - Train: J_r=-18.7325, J_c=1.4557, Lambda=0.4380, Actor Loss=-0.4343, Critic Loss=315.0532, Cost Critic Loss=0.0831, Entropy=20.7956\n",
      "2025-11-04 00:31:05,810 - PPOAgent - INFO - Starting episode: 8\n",
      "2025-11-04 00:31:17,368 - PPOAgent - INFO - Train: J_r=36.9676, J_c=1.4999, Lambda=0.5130, Actor Loss=-2.0098, Critic Loss=2642.0251, Cost Critic Loss=4.5896, Entropy=20.5862\n",
      "2025-11-04 00:31:17,368 - PPOAgent - INFO - Starting episode: 9\n",
      "2025-11-04 00:31:28,796 - PPOAgent - INFO - Train: J_r=-5.7163, J_c=1.1565, Lambda=0.5709, Actor Loss=-0.0930, Critic Loss=384.9316, Cost Critic Loss=0.0068, Entropy=22.4872\n",
      "2025-11-04 00:31:28,796 - PPOAgent - INFO - Starting episode: 10\n",
      "2025-11-04 00:31:40,292 - PPOAgent - INFO - Train: J_r=-12.4877, J_c=1.5712, Lambda=0.6494, Actor Loss=1.0235, Critic Loss=3216.3870, Cost Critic Loss=0.3975, Entropy=23.7049\n",
      "2025-11-04 00:31:40,292 - PPOAgent - INFO - Starting episode: 11\n",
      "2025-11-04 00:31:51,733 - PPOAgent - INFO - Train: J_r=-2.1071, J_c=1.8165, Lambda=0.7402, Actor Loss=-1.3188, Critic Loss=329.4682, Cost Critic Loss=1.3157, Entropy=24.0099\n",
      "2025-11-04 00:31:51,733 - PPOAgent - INFO - Starting episode: 12\n",
      "2025-11-04 00:32:03,134 - PPOAgent - INFO - Train: J_r=8.5945, J_c=1.8927, Lambda=0.8349, Actor Loss=-0.2444, Critic Loss=377.7351, Cost Critic Loss=0.0475, Entropy=23.9666\n",
      "2025-11-04 00:32:03,134 - PPOAgent - INFO - Starting episode: 13\n",
      "2025-11-04 00:32:14,567 - PPOAgent - INFO - Train: J_r=-6.1653, J_c=1.7559, Lambda=0.9227, Actor Loss=-1.1493, Critic Loss=38.8934, Cost Critic Loss=1.5125, Entropy=23.6861\n",
      "2025-11-04 00:32:14,568 - PPOAgent - INFO - Starting episode: 14\n",
      "2025-11-04 00:32:26,138 - PPOAgent - INFO - Train: J_r=-19.1955, J_c=1.3258, Lambda=0.9890, Actor Loss=0.5576, Critic Loss=1357.5870, Cost Critic Loss=0.1471, Entropy=24.4136\n",
      "2025-11-04 00:32:26,138 - PPOAgent - INFO - Starting episode: 15\n",
      "2025-11-04 00:32:37,376 - PPOAgent - INFO - Train: J_r=16.1816, J_c=2.3709, Lambda=1.1075, Actor Loss=0.2124, Critic Loss=25.6845, Cost Critic Loss=0.0694, Entropy=25.0982\n",
      "2025-11-04 00:32:37,376 - PPOAgent - INFO - Starting episode: 16\n",
      "2025-11-04 00:32:48,770 - PPOAgent - INFO - Train: J_r=7.8827, J_c=1.7223, Lambda=1.1936, Actor Loss=-1.6402, Critic Loss=2008.4091, Cost Critic Loss=0.0341, Entropy=25.3244\n",
      "2025-11-04 00:32:48,770 - PPOAgent - INFO - Starting episode: 17\n",
      "2025-11-04 00:33:00,251 - PPOAgent - INFO - Train: J_r=33.7496, J_c=1.3512, Lambda=1.2612, Actor Loss=-2.7375, Critic Loss=2172.8286, Cost Critic Loss=1.1020, Entropy=25.1358\n",
      "2025-11-04 00:33:00,251 - PPOAgent - INFO - Starting episode: 18\n",
      "2025-11-04 00:33:11,904 - PPOAgent - INFO - Train: J_r=-38.1192, J_c=0.9320, Lambda=1.3078, Actor Loss=0.6869, Critic Loss=2472.9211, Cost Critic Loss=0.1498, Entropy=25.0616\n",
      "2025-11-04 00:33:11,904 - PPOAgent - INFO - Starting episode: 19\n",
      "2025-11-04 00:33:23,172 - PPOAgent - INFO - Train: J_r=28.9185, J_c=2.2417, Lambda=1.4199, Actor Loss=-2.5747, Critic Loss=2564.4197, Cost Critic Loss=0.9795, Entropy=24.8824\n",
      "2025-11-04 00:33:23,172 - PPOAgent - INFO - Starting episode: 20\n",
      "2025-11-04 00:33:34,408 - PPOAgent - INFO - Train: J_r=1.8494, J_c=2.2441, Lambda=1.5321, Actor Loss=-0.2128, Critic Loss=450.1154, Cost Critic Loss=0.0520, Entropy=24.7732\n",
      "2025-11-04 00:33:34,408 - PPOAgent - INFO - Starting episode: 21\n",
      "2025-11-04 00:33:45,828 - PPOAgent - INFO - Train: J_r=-25.4293, J_c=1.7475, Lambda=1.6194, Actor Loss=3.6860, Critic Loss=1328.6476, Cost Critic Loss=3.0955, Entropy=24.5780\n",
      "2025-11-04 00:33:45,828 - PPOAgent - INFO - Starting episode: 22\n",
      "2025-11-04 00:33:57,192 - PPOAgent - INFO - Train: J_r=-15.3294, J_c=1.7860, Lambda=1.7087, Actor Loss=0.8504, Critic Loss=1170.1881, Cost Critic Loss=1.7141, Entropy=24.1692\n",
      "2025-11-04 00:33:57,192 - PPOAgent - INFO - Starting episode: 23\n",
      "2025-11-04 00:34:08,423 - PPOAgent - INFO - Train: J_r=26.5556, J_c=2.1093, Lambda=1.8142, Actor Loss=-0.5875, Critic Loss=48.8160, Cost Critic Loss=0.0656, Entropy=23.5493\n",
      "2025-11-04 00:34:08,423 - PPOAgent - INFO - Starting episode: 24\n",
      "2025-11-04 00:34:19,785 - PPOAgent - INFO - Train: J_r=-15.5751, J_c=1.4856, Lambda=1.8885, Actor Loss=-2.6958, Critic Loss=36.3311, Cost Critic Loss=0.3393, Entropy=23.2367\n",
      "2025-11-04 00:34:19,785 - PPOAgent - INFO - Starting episode: 25\n",
      "2025-11-04 00:34:31,086 - PPOAgent - INFO - Train: J_r=29.4723, J_c=2.2694, Lambda=2.0020, Actor Loss=-0.9292, Critic Loss=628.9749, Cost Critic Loss=0.0651, Entropy=23.1516\n",
      "2025-11-04 00:34:31,086 - PPOAgent - INFO - Starting episode: 26\n",
      "2025-11-04 00:34:42,575 - PPOAgent - INFO - Train: J_r=-16.3480, J_c=1.5669, Lambda=2.0803, Actor Loss=-4.3221, Critic Loss=808.6656, Cost Critic Loss=0.0885, Entropy=23.1362\n",
      "2025-11-04 00:34:42,576 - PPOAgent - INFO - Starting episode: 27\n",
      "2025-11-04 00:34:54,273 - PPOAgent - INFO - Train: J_r=-14.4325, J_c=0.6477, Lambda=2.1127, Actor Loss=1.4307, Critic Loss=7.0759, Cost Critic Loss=0.9361, Entropy=22.9232\n",
      "2025-11-04 00:34:54,273 - PPOAgent - INFO - Starting episode: 28\n",
      "2025-11-04 00:35:05,682 - PPOAgent - INFO - Train: J_r=-3.8139, J_c=1.6325, Lambda=2.1943, Actor Loss=-2.5616, Critic Loss=1281.2655, Cost Critic Loss=5.2737, Entropy=22.5810\n",
      "2025-11-04 00:35:05,682 - PPOAgent - INFO - Starting episode: 29\n",
      "2025-11-04 00:35:17,233 - PPOAgent - INFO - Train: J_r=-28.1550, J_c=1.0218, Lambda=2.2454, Actor Loss=1.0482, Critic Loss=1019.8677, Cost Critic Loss=4.2714, Entropy=21.9670\n",
      "2025-11-04 00:35:17,233 - PPOAgent - INFO - Starting episode: 30\n",
      "2025-11-04 00:35:28,607 - PPOAgent - INFO - Train: J_r=24.8627, J_c=1.4183, Lambda=2.3163, Actor Loss=-1.8828, Critic Loss=2141.2097, Cost Critic Loss=0.5109, Entropy=22.7527\n",
      "2025-11-04 00:35:28,607 - PPOAgent - INFO - Starting episode: 31\n",
      "2025-11-04 00:35:39,983 - PPOAgent - INFO - Train: J_r=-2.0436, J_c=1.5588, Lambda=2.3943, Actor Loss=1.5917, Critic Loss=12.7895, Cost Critic Loss=1.7386, Entropy=23.3904\n",
      "2025-11-04 00:35:39,984 - PPOAgent - INFO - Starting episode: 32\n",
      "2025-11-04 00:35:51,359 - PPOAgent - INFO - Train: J_r=17.2590, J_c=1.7777, Lambda=2.4832, Actor Loss=0.8828, Critic Loss=35.5864, Cost Critic Loss=1.8283, Entropy=23.4340\n",
      "2025-11-04 00:35:51,359 - PPOAgent - INFO - Starting episode: 33\n",
      "2025-11-04 00:36:02,735 - PPOAgent - INFO - Train: J_r=-11.1607, J_c=1.9077, Lambda=2.5785, Actor Loss=-0.6897, Critic Loss=95.7304, Cost Critic Loss=0.0592, Entropy=22.8299\n",
      "2025-11-04 00:36:02,736 - PPOAgent - INFO - Starting episode: 34\n",
      "2025-11-04 00:36:14,187 - PPOAgent - INFO - Train: J_r=9.1822, J_c=1.3294, Lambda=2.6450, Actor Loss=-2.4739, Critic Loss=83.3192, Cost Critic Loss=0.7874, Entropy=22.5940\n",
      "2025-11-04 00:36:14,187 - PPOAgent - INFO - Starting episode: 35\n",
      "2025-11-04 00:36:25,828 - PPOAgent - INFO - Train: J_r=-3.8718, J_c=0.9390, Lambda=2.6920, Actor Loss=5.4963, Critic Loss=65.8204, Cost Critic Loss=0.0246, Entropy=20.7632\n",
      "2025-11-04 00:36:25,828 - PPOAgent - INFO - Starting episode: 36\n",
      "2025-11-04 00:36:37,289 - PPOAgent - INFO - Train: J_r=9.4627, J_c=1.5134, Lambda=2.7676, Actor Loss=1.0254, Critic Loss=278.8093, Cost Critic Loss=0.1185, Entropy=19.6519\n",
      "2025-11-04 00:36:37,289 - PPOAgent - INFO - Starting episode: 37\n",
      "Energy Delta=254.4844, Total Traffic Demand=47.0000, Reward=-54.1456\n",
      "2025-11-04 00:36:48,924 - PPOAgent - INFO - Train: J_r=-25.9849, J_c=0.5084, Lambda=2.7931, Actor Loss=-2.6087, Critic Loss=147.5346, Cost Critic Loss=0.2889, Entropy=19.4690\n",
      "2025-11-04 00:36:48,924 - PPOAgent - INFO - Starting episode: 38\n",
      "2025-11-04 00:37:00,499 - PPOAgent - INFO - Train: J_r=10.0147, J_c=1.1958, Lambda=2.8528, Actor Loss=-3.1789, Critic Loss=178.2040, Cost Critic Loss=3.1644, Entropy=20.7608\n",
      "2025-11-04 00:37:00,499 - PPOAgent - INFO - Starting episode: 39\n",
      "2025-11-04 00:37:12,191 - PPOAgent - INFO - Train: J_r=16.7235, J_c=0.9053, Lambda=2.8981, Actor Loss=0.3391, Critic Loss=396.1496, Cost Critic Loss=0.1530, Entropy=22.3493\n",
      "2025-11-04 00:37:12,192 - PPOAgent - INFO - Starting episode: 40\n",
      "2025-11-04 00:37:23,824 - PPOAgent - INFO - Train: J_r=-40.0911, J_c=0.8026, Lambda=2.9382, Actor Loss=3.0598, Critic Loss=5543.6074, Cost Critic Loss=0.5689, Entropy=22.5676\n",
      "2025-11-04 00:37:23,824 - PPOAgent - INFO - Starting episode: 41\n",
      "2025-11-04 00:37:35,354 - PPOAgent - INFO - Train: J_r=23.8871, J_c=1.1761, Lambda=2.9970, Actor Loss=0.1057, Critic Loss=4928.2407, Cost Critic Loss=0.0463, Entropy=22.5046\n",
      "2025-11-04 00:37:35,354 - PPOAgent - INFO - Starting episode: 42\n",
      "2025-11-04 00:37:46,767 - PPOAgent - INFO - Train: J_r=-8.0467, J_c=1.4603, Lambda=3.0701, Actor Loss=-0.5745, Critic Loss=2.8908, Cost Critic Loss=0.5459, Entropy=21.5650\n",
      "2025-11-04 00:37:46,768 - PPOAgent - INFO - Starting episode: 43\n",
      "2025-11-04 00:37:58,218 - PPOAgent - INFO - Train: J_r=-14.1723, J_c=0.7536, Lambda=3.1077, Actor Loss=-0.0521, Critic Loss=4512.5957, Cost Critic Loss=0.4150, Entropy=21.0105\n",
      "2025-11-04 00:37:58,218 - PPOAgent - INFO - Starting episode: 44\n",
      "2025-11-04 00:38:09,702 - PPOAgent - INFO - Train: J_r=29.9443, J_c=1.3336, Lambda=3.1744, Actor Loss=2.9393, Critic Loss=225.8367, Cost Critic Loss=2.5921, Entropy=20.7373\n",
      "2025-11-04 00:38:09,702 - PPOAgent - INFO - Starting episode: 45\n",
      "2025-11-04 00:38:21,294 - PPOAgent - INFO - Train: J_r=-11.8178, J_c=1.0773, Lambda=3.2283, Actor Loss=1.9416, Critic Loss=10463.2549, Cost Critic Loss=3.2127, Entropy=19.9760\n",
      "2025-11-04 00:38:21,294 - PPOAgent - INFO - Starting episode: 46\n",
      "2025-11-04 00:38:32,678 - PPOAgent - INFO - Train: J_r=12.7610, J_c=1.7943, Lambda=3.3180, Actor Loss=-2.2669, Critic Loss=3872.9390, Cost Critic Loss=0.2821, Entropy=19.6689\n",
      "2025-11-04 00:38:32,678 - PPOAgent - INFO - Starting episode: 47\n",
      "2025-11-04 00:38:44,395 - PPOAgent - INFO - Train: J_r=-11.1143, J_c=0.6155, Lambda=3.3488, Actor Loss=1.9464, Critic Loss=2688.0933, Cost Critic Loss=0.0534, Entropy=19.8633\n",
      "2025-11-04 00:38:44,395 - PPOAgent - INFO - Starting episode: 48\n",
      "2025-11-04 00:38:56,028 - PPOAgent - INFO - Train: J_r=-16.4985, J_c=0.8808, Lambda=3.3928, Actor Loss=-6.3108, Critic Loss=39.4375, Cost Critic Loss=0.4968, Entropy=21.0902\n",
      "2025-11-04 00:38:56,028 - PPOAgent - INFO - Starting episode: 49\n",
      "Step 50/4096: Energy: 0.348 kWh, Power: 25.6 kW, Drop Rate: 3.22%\n",
      "Drop rate violation: 3.22% > 1%\n",
      "Step 50/4096: Energy: 0.348 kWh, Power: 25.7 kW, Drop Rate: 1.84%\n",
      "Drop rate violation: 1.84% > 1%\n",
      "Step 50/4096: Energy: 0.348 kWh, Power: 25.6 kW, Drop Rate: 2.23%\n",
      "Drop rate violation: 2.23% > 1%\n",
      "Step 50/4096: Energy: 0.348 kWh, Power: 25.9 kW, Drop Rate: 0.87%\n",
      "2025-11-04 00:39:07,500 - PPOAgent - INFO - Train: J_r=9.0267, J_c=1.0736, Lambda=3.4465, Actor Loss=-0.6686, Critic Loss=275.7529, Cost Critic Loss=0.8645, Entropy=21.5698\n",
      "2025-11-04 00:39:07,501 - PPOAgent - INFO - Starting episode: 50\n",
      "2025-11-04 00:39:19,109 - PPOAgent - INFO - Train: J_r=2.2359, J_c=0.7597, Lambda=3.4845, Actor Loss=0.7650, Critic Loss=199.0548, Cost Critic Loss=0.0625, Entropy=21.2059\n",
      "2025-11-04 00:39:19,109 - PPOAgent - INFO - Starting episode: 51\n",
      "2025-11-04 00:39:30,604 - PPOAgent - INFO - Train: J_r=29.9586, J_c=0.8941, Lambda=3.5292, Actor Loss=0.2667, Critic Loss=9421.3545, Cost Critic Loss=0.1097, Entropy=21.3075\n",
      "2025-11-04 00:39:30,604 - PPOAgent - INFO - Starting episode: 52\n",
      "2025-11-04 00:39:42,369 - PPOAgent - INFO - Train: J_r=-20.0714, J_c=0.5572, Lambda=3.5570, Actor Loss=-0.1205, Critic Loss=4.5874, Cost Critic Loss=0.0252, Entropy=21.8888\n",
      "2025-11-04 00:39:42,369 - PPOAgent - INFO - Starting episode: 53\n",
      "2025-11-04 00:39:53,854 - PPOAgent - INFO - Train: J_r=-18.4169, J_c=1.1431, Lambda=3.6142, Actor Loss=-0.0277, Critic Loss=6186.1792, Cost Critic Loss=0.1901, Entropy=22.7447\n",
      "2025-11-04 00:39:53,854 - PPOAgent - INFO - Starting episode: 54\n",
      "2025-11-04 00:40:05,528 - PPOAgent - INFO - Train: J_r=-14.1626, J_c=0.6385, Lambda=3.6461, Actor Loss=-0.9769, Critic Loss=1046.1344, Cost Critic Loss=0.4573, Entropy=22.8439\n",
      "2025-11-04 00:40:05,529 - PPOAgent - INFO - Starting episode: 55\n",
      "2025-11-04 00:40:16,787 - PPOAgent - INFO - Train: J_r=47.0099, J_c=2.0256, Lambda=3.7474, Actor Loss=-4.3344, Critic Loss=9506.6250, Cost Critic Loss=0.0007, Entropy=22.1100\n",
      "2025-11-04 00:40:16,787 - PPOAgent - INFO - Starting episode: 56\n",
      "2025-11-04 00:40:28,271 - PPOAgent - INFO - Train: J_r=-14.7613, J_c=1.2170, Lambda=3.8083, Actor Loss=-17.7030, Critic Loss=729.2950, Cost Critic Loss=2.7866, Entropy=22.2679\n",
      "2025-11-04 00:40:28,271 - PPOAgent - INFO - Starting episode: 57\n",
      "2025-11-04 00:40:39,836 - PPOAgent - INFO - Train: J_r=-25.8118, J_c=1.0019, Lambda=3.8584, Actor Loss=-3.5307, Critic Loss=192.7146, Cost Critic Loss=0.2644, Entropy=22.3740\n",
      "2025-11-04 00:40:39,836 - PPOAgent - INFO - Starting episode: 58\n",
      "2025-11-04 00:40:51,533 - PPOAgent - INFO - Train: J_r=18.1011, J_c=0.6826, Lambda=3.8925, Actor Loss=0.5690, Critic Loss=1809.1279, Cost Critic Loss=0.3377, Entropy=22.9366\n",
      "2025-11-04 00:40:51,533 - PPOAgent - INFO - Starting episode: 59\n",
      "2025-11-04 00:41:03,224 - PPOAgent - INFO - Train: J_r=3.9576, J_c=0.7051, Lambda=3.9277, Actor Loss=-5.0552, Critic Loss=40.2118, Cost Critic Loss=1.3691, Entropy=23.5738\n",
      "2025-11-04 00:41:03,225 - PPOAgent - INFO - Starting episode: 60\n",
      "2025-11-04 00:41:14,782 - PPOAgent - INFO - Train: J_r=-28.8726, J_c=1.0574, Lambda=3.9806, Actor Loss=2.4480, Critic Loss=3689.3459, Cost Critic Loss=0.4978, Entropy=24.0086\n",
      "2025-11-04 00:41:14,782 - PPOAgent - INFO - Starting episode: 61\n",
      "2025-11-04 00:41:26,047 - PPOAgent - INFO - Train: J_r=18.9208, J_c=1.7175, Lambda=4.0665, Actor Loss=-0.1125, Critic Loss=127.7338, Cost Critic Loss=0.4019, Entropy=24.0115\n",
      "2025-11-04 00:41:26,047 - PPOAgent - INFO - Starting episode: 62\n",
      "2025-11-04 00:41:37,433 - PPOAgent - INFO - Train: J_r=9.8298, J_c=1.1183, Lambda=4.1224, Actor Loss=-2.0064, Critic Loss=5.9456, Cost Critic Loss=0.0359, Entropy=23.7776\n",
      "2025-11-04 00:41:37,434 - PPOAgent - INFO - Starting episode: 63\n",
      "2025-11-04 00:41:49,110 - PPOAgent - INFO - Train: J_r=-12.6641, J_c=0.7728, Lambda=4.1610, Actor Loss=-0.3256, Critic Loss=22.1310, Cost Critic Loss=0.9307, Entropy=23.1826\n",
      "2025-11-04 00:41:49,110 - PPOAgent - INFO - Starting episode: 64\n",
      "2025-11-04 00:42:00,546 - PPOAgent - INFO - Train: J_r=-1.6964, J_c=1.4375, Lambda=4.2329, Actor Loss=-1.9373, Critic Loss=79.3798, Cost Critic Loss=0.2334, Entropy=23.0482\n",
      "2025-11-04 00:42:00,547 - PPOAgent - INFO - Starting episode: 65\n",
      "Energy Delta=-6.7910, Total Traffic Demand=31.0000, Reward=2.1907\n",
      "2025-11-04 00:42:12,077 - PPOAgent - INFO - Train: J_r=6.0744, J_c=1.2837, Lambda=4.2971, Actor Loss=-6.9477, Critic Loss=0.5474, Cost Critic Loss=2.6689, Entropy=23.0211\n",
      "2025-11-04 00:42:12,077 - PPOAgent - INFO - Starting episode: 66\n",
      "2025-11-04 00:42:23,795 - PPOAgent - INFO - Train: J_r=-18.8798, J_c=0.6380, Lambda=4.3290, Actor Loss=4.1661, Critic Loss=372.2541, Cost Critic Loss=0.1199, Entropy=23.1732\n",
      "2025-11-04 00:42:23,796 - PPOAgent - INFO - Starting episode: 67\n",
      "2025-11-04 00:42:35,494 - PPOAgent - INFO - Train: J_r=-13.7108, J_c=0.5375, Lambda=4.3559, Actor Loss=1.3267, Critic Loss=0.3965, Cost Critic Loss=0.0353, Entropy=23.2263\n",
      "2025-11-04 00:42:35,494 - PPOAgent - INFO - Starting episode: 68\n",
      "2025-11-04 00:42:47,263 - PPOAgent - INFO - Train: J_r=-19.6166, J_c=0.4128, Lambda=4.3765, Actor Loss=-2.3222, Critic Loss=477.8146, Cost Critic Loss=0.5825, Entropy=22.8057\n",
      "2025-11-04 00:42:47,263 - PPOAgent - INFO - Starting episode: 69\n",
      "2025-11-04 00:42:58,970 - PPOAgent - INFO - Train: J_r=24.2287, J_c=0.6899, Lambda=4.4110, Actor Loss=0.6649, Critic Loss=1121.2987, Cost Critic Loss=0.2371, Entropy=22.0613\n",
      "2025-11-04 00:42:58,970 - PPOAgent - INFO - Starting episode: 70\n",
      "2025-11-04 00:43:10,387 - PPOAgent - INFO - Train: J_r=6.0562, J_c=1.0077, Lambda=4.4614, Actor Loss=-3.3499, Critic Loss=3007.9871, Cost Critic Loss=0.1295, Entropy=22.5383\n",
      "2025-11-04 00:43:10,387 - PPOAgent - INFO - Starting episode: 71\n",
      "2025-11-04 00:43:22,130 - PPOAgent - INFO - Train: J_r=18.4857, J_c=0.5020, Lambda=4.4865, Actor Loss=-6.1440, Critic Loss=249.5190, Cost Critic Loss=0.9390, Entropy=23.0219\n",
      "2025-11-04 00:43:22,130 - PPOAgent - INFO - Starting episode: 72\n",
      "2025-11-04 00:43:33,855 - PPOAgent - INFO - Train: J_r=-29.4361, J_c=0.3441, Lambda=4.5037, Actor Loss=2.2350, Critic Loss=928.4998, Cost Critic Loss=0.4648, Entropy=22.8462\n",
      "2025-11-04 00:43:33,855 - PPOAgent - INFO - Starting episode: 73\n",
      "2025-11-04 00:43:45,372 - PPOAgent - INFO - Train: J_r=11.8947, J_c=1.1928, Lambda=4.5633, Actor Loss=5.0590, Critic Loss=36.0977, Cost Critic Loss=4.2511, Entropy=22.3066\n",
      "2025-11-04 00:43:45,372 - PPOAgent - INFO - Starting episode: 74\n",
      "2025-11-04 00:43:57,003 - PPOAgent - INFO - Train: J_r=-19.9530, J_c=0.6819, Lambda=4.5974, Actor Loss=1.7280, Critic Loss=34.0068, Cost Critic Loss=3.4327, Entropy=22.1948\n",
      "2025-11-04 00:43:57,003 - PPOAgent - INFO - Starting episode: 75\n",
      "2025-11-04 00:44:08,722 - PPOAgent - INFO - Train: J_r=6.3077, J_c=0.6436, Lambda=4.6296, Actor Loss=0.4152, Critic Loss=1567.0308, Cost Critic Loss=2.6096, Entropy=21.8165\n",
      "2025-11-04 00:44:08,723 - PPOAgent - INFO - Starting episode: 76\n",
      "2025-11-04 00:44:20,486 - PPOAgent - INFO - Train: J_r=-5.5096, J_c=0.2977, Lambda=4.6445, Actor Loss=-4.0596, Critic Loss=42.3107, Cost Critic Loss=0.2375, Entropy=22.0457\n",
      "2025-11-04 00:44:20,486 - PPOAgent - INFO - Starting episode: 77\n",
      "2025-11-04 00:44:32,240 - PPOAgent - INFO - Train: J_r=-10.7447, J_c=0.3649, Lambda=4.6627, Actor Loss=4.4374, Critic Loss=255.4230, Cost Critic Loss=0.0118, Entropy=22.0814\n",
      "2025-11-04 00:44:32,241 - PPOAgent - INFO - Starting episode: 78\n",
      "2025-11-04 00:44:44,020 - PPOAgent - INFO - Train: J_r=24.2588, J_c=0.4522, Lambda=4.6854, Actor Loss=-3.5437, Critic Loss=62.9886, Cost Critic Loss=0.2627, Entropy=21.8453\n",
      "2025-11-04 00:44:44,021 - PPOAgent - INFO - Starting episode: 79\n",
      "2025-11-04 00:44:55,739 - PPOAgent - INFO - Train: J_r=-12.6892, J_c=0.5491, Lambda=4.7128, Actor Loss=5.2668, Critic Loss=218.9893, Cost Critic Loss=0.0132, Entropy=21.9619\n",
      "2025-11-04 00:44:55,739 - PPOAgent - INFO - Starting episode: 80\n",
      "2025-11-04 00:45:07,602 - PPOAgent - INFO - Train: J_r=13.7788, J_c=0.1000, Lambda=4.7178, Actor Loss=2.5703, Critic Loss=507.9514, Cost Critic Loss=0.0005, Entropy=22.1938\n",
      "2025-11-04 00:45:07,602 - PPOAgent - INFO - Starting episode: 81\n",
      "2025-11-04 00:45:19,308 - PPOAgent - INFO - Train: J_r=-16.0251, J_c=0.5369, Lambda=4.7446, Actor Loss=4.5844, Critic Loss=214.2261, Cost Critic Loss=0.8281, Entropy=22.0759\n",
      "2025-11-04 00:45:19,309 - PPOAgent - INFO - Starting episode: 82\n",
      "2025-11-04 00:45:30,999 - PPOAgent - INFO - Train: J_r=13.0134, J_c=0.6270, Lambda=4.7760, Actor Loss=1.4885, Critic Loss=1291.6067, Cost Critic Loss=0.1220, Entropy=22.3355\n",
      "2025-11-04 00:45:30,999 - PPOAgent - INFO - Starting episode: 83\n",
      "2025-11-04 00:45:42,626 - PPOAgent - INFO - Train: J_r=-17.0454, J_c=0.8648, Lambda=4.8192, Actor Loss=0.6553, Critic Loss=29.3138, Cost Critic Loss=0.0148, Entropy=22.9912\n",
      "2025-11-04 00:45:42,626 - PPOAgent - INFO - Starting episode: 84\n",
      "2025-11-04 00:45:54,337 - PPOAgent - INFO - Train: J_r=-5.3332, J_c=0.5075, Lambda=4.8446, Actor Loss=2.3749, Critic Loss=318.8287, Cost Critic Loss=0.3970, Entropy=23.4483\n",
      "2025-11-04 00:45:54,337 - PPOAgent - INFO - Starting episode: 85\n",
      "2025-11-04 00:46:05,699 - PPOAgent - INFO - Train: J_r=23.9076, J_c=1.2448, Lambda=4.9069, Actor Loss=-9.8947, Critic Loss=5.5477, Cost Critic Loss=0.7360, Entropy=23.6836\n",
      "2025-11-04 00:46:05,700 - PPOAgent - INFO - Starting episode: 86\n",
      "Drop=2.4080%, Latency=27.2407ms, CPU=95.0000%, PRB=95.0000%\n",
      "QoS Cost: 1.4080\n",
      "Drop Violation=1.4080, Latency Violation=0.0000, CPU Violation=0.0000, PRB Violation=0.0000\n",
      "2025-11-04 00:46:17,147 - PPOAgent - INFO - Train: J_r=2.6251, J_c=0.9262, Lambda=4.9532, Actor Loss=3.2470, Critic Loss=22.2340, Cost Critic Loss=1.6226, Entropy=23.6432\n",
      "2025-11-04 00:46:17,147 - PPOAgent - INFO - Starting episode: 87\n",
      "2025-11-04 00:46:28,866 - PPOAgent - INFO - Train: J_r=-15.8113, J_c=0.5034, Lambda=4.9783, Actor Loss=-2.5742, Critic Loss=4.2080, Cost Critic Loss=0.8635, Entropy=23.9375\n",
      "2025-11-04 00:46:28,866 - PPOAgent - INFO - Starting episode: 88\n",
      "2025-11-04 00:46:40,460 - PPOAgent - INFO - Train: J_r=28.1745, J_c=0.8582, Lambda=5.0212, Actor Loss=-5.9877, Critic Loss=6725.9307, Cost Critic Loss=0.0228, Entropy=24.1646\n",
      "2025-11-04 00:46:40,460 - PPOAgent - INFO - Starting episode: 89\n",
      "2025-11-04 00:46:52,106 - PPOAgent - INFO - Train: J_r=-8.9450, J_c=0.6548, Lambda=5.0540, Actor Loss=-2.4226, Critic Loss=1.6054, Cost Critic Loss=0.2010, Entropy=24.1436\n",
      "2025-11-04 00:46:52,106 - PPOAgent - INFO - Starting episode: 90\n",
      "2025-11-04 00:47:03,646 - PPOAgent - INFO - Train: J_r=-10.0139, J_c=0.9458, Lambda=5.1013, Actor Loss=0.9740, Critic Loss=196.4500, Cost Critic Loss=1.8951, Entropy=23.9389\n",
      "2025-11-04 00:47:03,646 - PPOAgent - INFO - Starting episode: 91\n",
      "2025-11-04 00:47:15,009 - PPOAgent - INFO - Train: J_r=50.6627, J_c=1.7498, Lambda=5.1888, Actor Loss=6.5694, Critic Loss=5067.6201, Cost Critic Loss=0.3892, Entropy=23.5098\n",
      "2025-11-04 00:47:15,009 - PPOAgent - INFO - Starting episode: 92\n",
      "2025-11-04 00:47:26,700 - PPOAgent - INFO - Train: J_r=-12.0520, J_c=0.5667, Lambda=5.2171, Actor Loss=-3.8068, Critic Loss=598.8342, Cost Critic Loss=0.3042, Entropy=22.8205\n",
      "2025-11-04 00:47:26,700 - PPOAgent - INFO - Starting episode: 93\n",
      "2025-11-04 00:47:38,296 - PPOAgent - INFO - Train: J_r=-25.3239, J_c=0.8530, Lambda=5.2598, Actor Loss=-15.5410, Critic Loss=963.4201, Cost Critic Loss=0.3654, Entropy=22.7977\n",
      "2025-11-04 00:47:38,296 - PPOAgent - INFO - Starting episode: 94\n",
      "2025-11-04 00:47:49,797 - PPOAgent - INFO - Train: J_r=4.9348, J_c=0.7248, Lambda=5.2960, Actor Loss=3.4862, Critic Loss=71.7404, Cost Critic Loss=0.0581, Entropy=22.7977\n",
      "2025-11-04 00:47:49,797 - PPOAgent - INFO - Starting episode: 95\n",
      "2025-11-04 00:48:01,531 - PPOAgent - INFO - Train: J_r=-15.5713, J_c=0.2843, Lambda=5.3102, Actor Loss=0.7707, Critic Loss=224.5874, Cost Critic Loss=0.0001, Entropy=22.7977\n",
      "2025-11-04 00:48:01,532 - PPOAgent - INFO - Starting episode: 96\n",
      "2025-11-04 00:48:13,048 - PPOAgent - INFO - Train: J_r=11.7744, J_c=1.2549, Lambda=5.3730, Actor Loss=0.1914, Critic Loss=1022.1327, Cost Critic Loss=0.0896, Entropy=22.7977\n",
      "2025-11-04 00:48:13,048 - PPOAgent - INFO - Starting episode: 97\n",
      "2025-11-04 00:48:24,665 - PPOAgent - INFO - Train: J_r=-9.9159, J_c=0.9931, Lambda=5.4226, Actor Loss=0.0667, Critic Loss=1357.9629, Cost Critic Loss=0.9373, Entropy=22.7977\n",
      "2025-11-04 00:48:24,665 - PPOAgent - INFO - Starting episode: 98\n",
      "2025-11-04 00:48:36,118 - PPOAgent - INFO - Train: J_r=20.9621, J_c=1.1276, Lambda=5.4790, Actor Loss=4.0078, Critic Loss=643.0864, Cost Critic Loss=1.0194, Entropy=22.7977\n",
      "2025-11-04 00:48:36,119 - PPOAgent - INFO - Starting episode: 99\n",
      "Step 100/4096: Energy: 0.706 kWh, Power: 25.9 kW, Drop Rate: 2.82%\n",
      "Drop rate violation: 2.82% > 1%\n",
      "Step 100/4096: Energy: 0.706 kWh, Power: 25.7 kW, Drop Rate: 2.34%\n",
      "Drop rate violation: 2.34% > 1%\n",
      "Step 100/4096: Energy: 0.706 kWh, Power: 25.9 kW, Drop Rate: 1.79%\n",
      "Drop rate violation: 1.79% > 1%\n",
      "Step 100/4096: Energy: 0.706 kWh, Power: 26.0 kW, Drop Rate: 0.65%\n",
      "2025-11-04 00:48:47,739 - PPOAgent - INFO - Train: J_r=-23.0654, J_c=0.9890, Lambda=5.5284, Actor Loss=8.6395, Critic Loss=854.0277, Cost Critic Loss=2.7268, Entropy=22.9048\n",
      "2025-11-04 00:48:47,739 - PPOAgent - INFO - Starting episode: 100\n",
      "2025-11-04 00:48:59,375 - PPOAgent - INFO - Train: J_r=19.0021, J_c=0.8920, Lambda=5.5730, Actor Loss=0.5902, Critic Loss=420.8360, Cost Critic Loss=2.8071, Entropy=22.7977\n",
      "2025-11-04 00:48:59,375 - PPOAgent - INFO - Starting episode: 101\n",
      "  Step 100/4096: 4/4 envs active\n",
      "2025-11-04 00:49:10,938 - PPOAgent - INFO - Train: J_r=10.9745, J_c=0.9346, Lambda=5.6198, Actor Loss=-4.1195, Critic Loss=276.8573, Cost Critic Loss=0.1131, Entropy=22.7977\n",
      "2025-11-04 00:49:10,938 - PPOAgent - INFO - Starting episode: 102\n",
      "2025-11-04 00:49:22,558 - PPOAgent - INFO - Train: J_r=19.1492, J_c=0.9916, Lambda=5.6694, Actor Loss=-2.0342, Critic Loss=523.2599, Cost Critic Loss=1.4439, Entropy=22.7977\n",
      "2025-11-04 00:49:22,558 - PPOAgent - INFO - Starting episode: 103\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 253, in <module>\n",
      "    main(n_parallel_envs=args.n_envs, scenarios_dir=args.scenarios_dir)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 67, in main\n",
      "    results = run_scenario_with_rl_agent_parallel(\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 182, in run_scenario_with_rl_agent_parallel\n",
      "    next_obs, rewards, new_dones, infos = envs.step(actions)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in step\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in <listcomp>\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    num_envs = config['n_envs']\n",
    "\n",
    "!python3 app/main_run_scenarios_parallel.py --scenarios-dir app/train_scenarios --n-envs $num_envs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
