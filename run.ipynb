{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/nguyenduchuyiu/RL-for-5G-Energy-Saving.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RL-for-5G-Energy-Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/energy_agent/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/energy_agent/config.yaml\n",
    "training_mode: True\n",
    "use_gpu: True\n",
    "checkpoint_path: \"app/energy_agent/models/ppo_model_last.pth\"\n",
    "\n",
    "actor_lr: 0.0001\n",
    "critic_lr: 0.0003\n",
    "\n",
    "energy_coeff: 0.1\n",
    "drop_magnitude_penalty_coef: 100.0\n",
    "latency_magnitude_penalty_coef: 100.0\n",
    "cpu_magnitude_penalty_coef: 100.0\n",
    "prb_magnitude_penalty_coef: 100.0\n",
    "improvement_coeff: 5.0\n",
    "\n",
    "violation_event_penalty: -5.0\n",
    "energy_consumption_penalty: -1000.0\n",
    "\n",
    "gamma: 0.99\n",
    "lambda_gae: 0.95\n",
    "clip_epsilon: 0.2\n",
    "ppo_epochs: 8\n",
    "batch_size: 32\n",
    "buffer_size: 512\n",
    "n_envs: 4\n",
    "hidden_dim: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/dense_urban.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/dense_urban.json\n",
    "{\n",
    "  \"name\": \"Dense Urban\",\n",
    "  \"description\": \"3GPP Dense urban with macro and micro cells\",\n",
    "  \"deploymentScenario\": \"dense_urban\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"two_layer\",\n",
    "  \"isd\": 200,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"Uniform/macro\",\n",
    "  \"ueSpeed\": 3,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 10,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 6144,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 20,\n",
    "  \"peakHourMultiplier\": 1.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app/train_scenarios/urban_macro.json\n",
    "    {\n",
    "  \"name\": \"3GPP Urban Macro\",\n",
    "  \"description\": \"3GPP Urban macro deployment scenario with large cells and continuous coverage\",\n",
    "  \"deploymentScenario\": \"urban_macro\",\n",
    "  \n",
    "  \"carrierFrequency\": 2e9,\n",
    "  \"systemBandwidth\": 100e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 500,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 30,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 25,\n",
    "  \"peakHourMultiplier\": 1.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app/train_scenarios/rural.json\n",
    "{\n",
    "  \"name\": \"3GPP Rural Macro\",\n",
    "  \"description\": \"3GPP Rural deployment scenario with wide area coverage for high speed vehicles\",\n",
    "  \"deploymentScenario\": \"rural\",\n",
    "  \n",
    "  \"carrierFrequency\": 700e6,\n",
    "  \"systemBandwidth\": 20e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 19,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 100,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 120,\n",
    "  \"indoorRatio\": 0.5,\n",
    "  \"outdoorSpeed\": 120,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -115,\n",
    "  \"rsrpTargetThreshold\": -105,\n",
    "  \"rsrpMeasurementThreshold\": -120,\n",
    "  \"dropCallThreshold\": 2,\n",
    "  \"latencyThreshold\": 100,\n",
    "  \"cpuThreshold\": 90,\n",
    "  \"prbThreshold\": 90,\n",
    "  \n",
    "  \"trafficLambda\": 10,\n",
    "  \"peakHourMultiplier\": 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huy/anaconda3/envs/mira/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\n",
      "=== Running Benchmark Suite (3 scenarios) ===\n",
      "Scenarios directory: app/train_scenarios/\n",
      "Using 4 parallel environments per scenario\n",
      "Loaded scenarios: ['dense_urban', 'rural', 'urban_macro']\n",
      "\n",
      "\n",
      "--- Scenario 1/3: dense_urban ---\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Created 4 parallel environments\n",
      "  Scenario: dense_urban\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "2025-10-23 14:10:07,968 - PPOAgent - INFO - PPO Agent initialized: 21 cells, 300 UEs\n",
      "2025-10-23 14:10:07,968 - PPOAgent - INFO - State dim: 1440, Action dim: 100\n",
      "2025-10-23 14:10:07,968 - PPOAgent - INFO - Device: cuda\n",
      "2025-10-23 14:10:07,968 - PPOAgent - INFO - No checkpoint found at app/energy_agent/models/ppo_model_last.pth\n",
      "Created 7 sites for dense_urban scenario\n",
      "Configuring cells for dense_urban scenario...\n",
      "Configured 21 cells for dense_urban scenario\n",
      "Created 7 sites for dense_urban scenario\n",
      "Configuring cells for dense_urban scenario...\n",
      "Configured 21 cells for dense_urban scenario\n",
      "Created 7 sites for dense_urban scenarioCreated 7 sites for dense_urban scenario\n",
      "\n",
      "Configuring cells for dense_urban scenario...Configuring cells for dense_urban scenario...\n",
      "\n",
      "Configured 21 cells for dense_urban scenarioConfigured 21 cells for dense_urban scenario\n",
      "\n",
      "Initialized 300 UEs for dense_urban scenario\n",
      "Initialized 300 UEs for dense_urban scenario\n",
      "Initialized 300 UEs for dense_urban scenario\n",
      "Initialized 300 UEs for dense_urban scenario\n",
      "===================Starting scenario===================\n",
      "===================Starting episode: 1===================\n",
      "Training with 4 parallel environments...\n",
      "Total steps: 6144\n",
      "total_reward:  -147.54097\n",
      "energy_efficiency_reward:  -25.658009\n",
      "drop_penalty:  -105.95456\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -10.023808\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -5.9046054\n",
      "total_reward:  -349.10757\n",
      "energy_efficiency_reward:  -12.295898\n",
      "drop_penalty:  -317.11084\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -13.83333\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -5.867489\n",
      "total_reward:  -135.98026\n",
      "energy_efficiency_reward:  -14.129297\n",
      "drop_penalty:  -105.95456\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -10.023808\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -5.8725815\n",
      "total_reward:  -233.56395\n",
      "energy_efficiency_reward:  -17.082228\n",
      "drop_penalty:  -198.64316\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -11.957787\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -5.880784\n",
      "total_reward:  -554.0688\n",
      "energy_efficiency_reward:  -450.19043\n",
      "drop_penalty:  -96.952415\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.22921622\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1551347\n",
      "total_reward:  -576.47845\n",
      "energy_efficiency_reward:  -457.63632\n",
      "drop_penalty:  -115.28589\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  3.5824752\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1387005\n",
      "total_reward:  -790.46765\n",
      "energy_efficiency_reward:  -464.8543\n",
      "drop_penalty:  -314.67456\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.774979\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1638436\n",
      "total_reward:  -934.3126\n",
      "energy_efficiency_reward:  -447.15567\n",
      "drop_penalty:  -476.139\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.8950825\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.122884\n",
      "total_reward:  -194.04355\n",
      "energy_efficiency_reward:  -8.75293\n",
      "drop_penalty:  -176.36053\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.7506462\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1794486\n",
      "total_reward:  -69.65049\n",
      "energy_efficiency_reward:  -6.7107425\n",
      "drop_penalty:  -57.413403\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.6309994\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.157342\n",
      "total_reward:  -1189.221\n",
      "energy_efficiency_reward:  24.096094\n",
      "drop_penalty:  -1197.7507\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -8.469325\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.09691\n",
      "total_reward:  -463.96295\n",
      "energy_efficiency_reward:  -8.40918\n",
      "drop_penalty:  -448.72797\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.32044291\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.146242\n",
      "total_reward:  -176.4428\n",
      "energy_efficiency_reward:  17.80547\n",
      "drop_penalty:  -186.91963\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.19864202\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1299887\n",
      "total_reward:  -419.09146\n",
      "energy_efficiency_reward:  23.589844\n",
      "drop_penalty:  -428.91473\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -6.67474\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.091814\n",
      "total_reward:  -27.918488\n",
      "energy_efficiency_reward:  8.0779295\n",
      "drop_penalty:  -43.103653\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  14.1817045\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.074471\n",
      "total_reward:  -76.95501\n",
      "energy_efficiency_reward:  -2.4445312\n",
      "drop_penalty:  -73.74426\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  6.386818\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1530323\n",
      "total_reward:  -298.0544\n",
      "energy_efficiency_reward:  5.8441405\n",
      "drop_penalty:  -295.01376\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.7710161\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.113755\n",
      "total_reward:  -226.5314\n",
      "energy_efficiency_reward:  32.591213\n",
      "drop_penalty:  -254.51787\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.3965275\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.001283\n",
      "total_reward:  -68.89783\n",
      "energy_efficiency_reward:  -9.5082035\n",
      "drop_penalty:  -51.94918\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.33956587\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1008825\n",
      "total_reward:  -220.82858\n",
      "energy_efficiency_reward:  27.277735\n",
      "drop_penalty:  -237.54988\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.479185\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.077261\n",
      "total_reward:  -630.0711\n",
      "energy_efficiency_reward:  -11.333594\n",
      "drop_penalty:  -607.8308\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.7614107\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.145237\n",
      "total_reward:  -401.38715\n",
      "energy_efficiency_reward:  -39.621094\n",
      "drop_penalty:  -353.22244\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.4322925\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1113415\n",
      "total_reward:  -212.79158\n",
      "energy_efficiency_reward:  -20.324804\n",
      "drop_penalty:  -182.08182\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.2276309\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1573405\n",
      "total_reward:  -139.89261\n",
      "energy_efficiency_reward:  -9.693946\n",
      "drop_penalty:  -125.23665\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.1421695\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1041884\n",
      "total_reward:  -156.62213\n",
      "energy_efficiency_reward:  13.326953\n",
      "drop_penalty:  -168.71953\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  5.8786592\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.108218\n",
      "total_reward:  -179.43225\n",
      "energy_efficiency_reward:  -4.8984375\n",
      "drop_penalty:  -170.31056\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.901702\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.124949\n",
      "total_reward:  -183.99376\n",
      "energy_efficiency_reward:  12.9769535\n",
      "drop_penalty:  -189.70767\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.14175534\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1212935\n",
      "total_reward:  -134.5149\n",
      "energy_efficiency_reward:  3.166797\n",
      "drop_penalty:  -130.46828\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.11800766\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0953918\n",
      "total_reward:  -177.19121\n",
      "energy_efficiency_reward:  -0.29746094\n",
      "drop_penalty:  -169.76433\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.020381212\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.109044\n",
      "total_reward:  -174.19492\n",
      "energy_efficiency_reward:  13.143555\n",
      "drop_penalty:  -180.06311\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.18691301\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.088439\n",
      "total_reward:  -152.3195\n",
      "energy_efficiency_reward:  -1.8570312\n",
      "drop_penalty:  -144.23157\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.89553833\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.126452\n",
      "total_reward:  -369.8833\n",
      "energy_efficiency_reward:  -2.4371095\n",
      "drop_penalty:  -356.56955\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.774463\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1021614\n",
      "total_reward:  -92.352776\n",
      "energy_efficiency_reward:  -14.813672\n",
      "drop_penalty:  -72.693146\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.3042357\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1501937\n",
      "total_reward:  -130.706\n",
      "energy_efficiency_reward:  -11.258789\n",
      "drop_penalty:  -113.7294\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.4019012\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.119713\n",
      "total_reward:  -788.0646\n",
      "energy_efficiency_reward:  15.948438\n",
      "drop_penalty:  -788.83215\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -8.09868\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.082151\n",
      "total_reward:  -578.35815\n",
      "energy_efficiency_reward:  6.981641\n",
      "drop_penalty:  -575.68756\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -2.5694394\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0827684\n",
      "total_reward:  -59.563675\n",
      "energy_efficiency_reward:  6.48418\n",
      "drop_penalty:  -59.34356\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.42788804\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.132182\n",
      "total_reward:  -121.60487\n",
      "energy_efficiency_reward:  -13.407618\n",
      "drop_penalty:  -101.34616\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.3058654\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1569567\n",
      "total_reward:  -42.27843\n",
      "energy_efficiency_reward:  1.0492188\n",
      "drop_penalty:  -47.006298\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  10.757887\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.079236\n",
      "total_reward:  -494.06924\n",
      "energy_efficiency_reward:  -7.1728516\n",
      "drop_penalty:  -480.83145\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.0377526\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1026926\n",
      "total_reward:  -534.1362\n",
      "energy_efficiency_reward:  1.2810547\n",
      "drop_penalty:  -520.621\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -7.66774\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.128623\n",
      "total_reward:  13.981247\n",
      "energy_efficiency_reward:  22.144728\n",
      "drop_penalty:  -5.5913463\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  4.5233088\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0954437\n",
      "total_reward:  -69.515854\n",
      "energy_efficiency_reward:  -10.702539\n",
      "drop_penalty:  -51.534164\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.17018437\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1089654\n",
      "total_reward:  -201.69594\n",
      "energy_efficiency_reward:  -11.06504\n",
      "drop_penalty:  -187.64691\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  4.1494346\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.133429\n",
      "total_reward:  -99.04189\n",
      "energy_efficiency_reward:  13.737891\n",
      "drop_penalty:  -111.87398\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  6.1846504\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.090462\n",
      "total_reward:  -28.89469\n",
      "energy_efficiency_reward:  -5.7400393\n",
      "drop_penalty:  -14.857894\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.1853689\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1113877\n",
      "total_reward:  -14.300578\n",
      "energy_efficiency_reward:  4.310352\n",
      "drop_penalty:  -13.469606\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.9556683\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0969925\n",
      "total_reward:  -504.70947\n",
      "energy_efficiency_reward:  -1.6070312\n",
      "drop_penalty:  -491.69138\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -4.2731953\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.137893\n",
      "total_reward:  -357.0148\n",
      "energy_efficiency_reward:  0.40683594\n",
      "drop_penalty:  -346.26462\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -4.067681\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.089332\n",
      "total_reward:  -348.68655\n",
      "energy_efficiency_reward:  -5.4458985\n",
      "drop_penalty:  -328.68832\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -7.425806\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1265154\n",
      "total_reward:  -241.26617\n",
      "energy_efficiency_reward:  -1.453125\n",
      "drop_penalty:  -226.72198\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -5.990037\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1010294\n",
      "total_reward:  -607.3441\n",
      "energy_efficiency_reward:  33.016994\n",
      "drop_penalty:  -631.82715\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.4877164\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.046179\n",
      "total_reward:  -308.44595\n",
      "energy_efficiency_reward:  -5.815039\n",
      "drop_penalty:  -296.22937\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.7039523\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.105485\n",
      "total_reward:  -507.27072\n",
      "energy_efficiency_reward:  6.9808593\n",
      "drop_penalty:  -504.96024\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -2.1842253\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1071243\n",
      "total_reward:  -209.84482\n",
      "energy_efficiency_reward:  -4.2128906\n",
      "drop_penalty:  -199.00017\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.48096895\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1127315\n",
      "total_reward:  -90.57649\n",
      "energy_efficiency_reward:  -6.419727\n",
      "drop_penalty:  -85.13511\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  8.042347\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0640116\n",
      "total_reward:  -128.1043\n",
      "energy_efficiency_reward:  17.83672\n",
      "drop_penalty:  -141.57454\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.6894665\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0559387\n",
      "total_reward:  -234.74603\n",
      "energy_efficiency_reward:  19.893164\n",
      "drop_penalty:  -250.92621\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  3.3388782\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0518656\n",
      "total_reward:  -145.36702\n",
      "energy_efficiency_reward:  7.7232423\n",
      "drop_penalty:  -147.00488\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.005907\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0912776\n",
      "total_reward:  -114.15464\n",
      "energy_efficiency_reward:  -32.864063\n",
      "drop_penalty:  -74.44451\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.309242\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.155301\n",
      "total_reward:  -487.55276\n",
      "energy_efficiency_reward:  -24.160156\n",
      "drop_penalty:  -451.547\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -4.7225738\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.12305\n",
      "total_reward:  -162.66843\n",
      "energy_efficiency_reward:  -9.5863285\n",
      "drop_penalty:  -147.86824\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.8646419\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.078494\n",
      "total_reward:  -93.59795\n",
      "energy_efficiency_reward:  -0.039453126\n",
      "drop_penalty:  -87.87366\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.4065415\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0913873\n",
      "total_reward:  -87.97962\n",
      "energy_efficiency_reward:  19.634766\n",
      "drop_penalty:  -99.81173\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.70189714\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.10076\n",
      "total_reward:  -92.40656\n",
      "energy_efficiency_reward:  6.4496093\n",
      "drop_penalty:  -97.50782\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  5.7567797\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1051345\n",
      "total_reward:  -146.57639\n",
      "energy_efficiency_reward:  -5.1597657\n",
      "drop_penalty:  -134.60791\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.28410196\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.092827\n",
      "total_reward:  -81.77142\n",
      "energy_efficiency_reward:  -9.974219\n",
      "drop_penalty:  -65.34573\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.6676227\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1190934\n",
      "total_reward:  -153.79935\n",
      "energy_efficiency_reward:  11.007617\n",
      "drop_penalty:  -156.45204\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.2847269\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.070183\n",
      "total_reward:  -409.79123\n",
      "energy_efficiency_reward:  21.11582\n",
      "drop_penalty:  -418.50223\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -5.358328\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0464797\n",
      "total_reward:  -444.42996\n",
      "energy_efficiency_reward:  -0.81406254\n",
      "drop_penalty:  -431.8825\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -4.638294\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0950885\n",
      "total_reward:  -0.859807\n",
      "energy_efficiency_reward:  1.1363281\n",
      "drop_penalty:  0.0\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  5.1198015\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1159368\n",
      "total_reward:  -73.615814\n",
      "energy_efficiency_reward:  -21.592773\n",
      "drop_penalty:  -47.776005\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.8831244\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.130163\n",
      "total_reward:  -824.0854\n",
      "energy_efficiency_reward:  -0.3966797\n",
      "drop_penalty:  -812.59937\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -4.0417695\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0475817\n",
      "total_reward:  -263.7572\n",
      "energy_efficiency_reward:  -9.431445\n",
      "drop_penalty:  -249.71338\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.5089085\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1212864\n",
      "total_reward:  -520.1\n",
      "energy_efficiency_reward:  23.923828\n",
      "drop_penalty:  -524.34406\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -12.630236\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0494823\n",
      "total_reward:  -205.54202\n",
      "energy_efficiency_reward:  0.45781252\n",
      "drop_penalty:  -195.24464\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -3.6262918\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.128891\n",
      "total_reward:  -289.70245\n",
      "energy_efficiency_reward:  -18.375391\n",
      "drop_penalty:  -270.29364\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  6.065228\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.098624\n",
      "total_reward:  -250.52045\n",
      "energy_efficiency_reward:  20.699024\n",
      "drop_penalty:  -263.93167\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.2240181\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.063789\n",
      "total_reward:  -5.877208\n",
      "energy_efficiency_reward:  -10.903125\n",
      "drop_penalty:  0.0\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  12.105685\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0797687\n",
      "total_reward:  -188.29921\n",
      "energy_efficiency_reward:  27.999609\n",
      "drop_penalty:  -209.00269\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.24501562\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0511146\n",
      "total_reward:  -67.86868\n",
      "energy_efficiency_reward:  -16.358398\n",
      "drop_penalty:  -49.186497\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  4.8202724\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1440644\n",
      "total_reward:  -186.54396\n",
      "energy_efficiency_reward:  -9.936719\n",
      "drop_penalty:  -171.1172\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  1.6013539\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.091391\n",
      "total_reward:  -50.48932\n",
      "energy_efficiency_reward:  -18.33379\n",
      "drop_penalty:  -22.237787\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -2.7870462\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1306953\n",
      "total_reward:  -112.9601\n",
      "energy_efficiency_reward:  -16.843555\n",
      "drop_penalty:  -91.50959\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.4909492\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.097902\n",
      "total_reward:  -445.54642\n",
      "energy_efficiency_reward:  17.713087\n",
      "drop_penalty:  -448.9532\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -7.211452\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.0948615\n",
      "total_reward:  -54.052258\n",
      "energy_efficiency_reward:  -7.8269534\n",
      "drop_penalty:  -42.494843\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  3.3826714\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1131325\n",
      "total_reward:  -54.142475\n",
      "energy_efficiency_reward:  -0.095507815\n",
      "drop_penalty:  -45.79825\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -1.1177546\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.130961\n",
      "total_reward:  -116.74784\n",
      "energy_efficiency_reward:  -7.7306643\n",
      "drop_penalty:  -101.63322\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.26458323\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.119376\n",
      "total_reward:  -259.63245\n",
      "energy_efficiency_reward:  8.603516\n",
      "drop_penalty:  -263.65866\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  2.493664\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.070963\n",
      "total_reward:  -55.459015\n",
      "energy_efficiency_reward:  -13.751563\n",
      "drop_penalty:  -34.884438\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  0.32831848\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.151332\n",
      "total_reward:  7.281118\n",
      "energy_efficiency_reward:  10.261329\n",
      "drop_penalty:  0.0\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  4.1222463\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.1024575\n",
      "total_reward:  -129.11748\n",
      "energy_efficiency_reward:  13.608203\n",
      "drop_penalty:  -134.86137\n",
      "latency_penalty:  0.0\n",
      "cpu_penalty:  0.0\n",
      "prb_penalty:  0.0\n",
      "drop_improvement:  -0.782727\n",
      "latency_improvement:  0.0\n",
      "energy_consumption_penalty:  -7.081576\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 253, in <module>\n",
      "    main(n_parallel_envs=args.n_envs, scenarios_dir=args.scenarios_dir)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 67, in main\n",
      "    results = run_scenario_with_rl_agent_parallel(\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 182, in run_scenario_with_rl_agent_parallel\n",
      "    next_obs, rewards, new_dones, infos = envs.step(actions)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in step\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in <listcomp>\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('app/energy_agent/config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    num_envs = config['n_envs']\n",
    "\n",
    "!python3 app/main_run_scenarios_parallel.py --n-envs {num_envs} --scenarios-dir app/train_scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app/energy_agent/config.yaml\n",
    "training_mode: False\n",
    "use_gpu: True\n",
    "checkpoint_path: \"app/energy_agent/models/ppo_model_6k.pth\"\n",
    "\n",
    "actor_lr: 0.0001\n",
    "critic_lr: 0.0003\n",
    "\n",
    "energy_coeff: 0.01\n",
    "drop_magnitude_penalty_coef: 1.0\n",
    "latency_magnitude_penalty_coef: 0.5\n",
    "cpu_magnitude_penalty_coef: 1.0\n",
    "prb_magnitude_penalty_coef: 1.0\n",
    "improvement_coeff: 0.5\n",
    "\n",
    "violation_event_penalty: -10.0\n",
    "energy_consumption_penalty: -10.0\n",
    "\n",
    "gamma: 0.99\n",
    "lambda_gae: 0.95\n",
    "clip_epsilon: 0.2\n",
    "ppo_epochs: 8\n",
    "batch_size: 64\n",
    "buffer_size: 2048\n",
    "n_envs: 4\n",
    "hidden_dim: 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 app/main_run_scenarios_python.py --scenarios-dir app/test_scenarios"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
