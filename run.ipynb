{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RL-for-5G-Energy-Saving'...\n"
     ]
    }
   ],
   "source": [
    "!git clone -b lagrangian-ppo --single-branch https://github.com/nguyenduchuyiu/RL-for-5G-Energy-Saving.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RL-for-5G-Energy-Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/dense_urban.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/dense_urban.json\n",
    "{\n",
    "  \"name\": \"Dense Urban\",\n",
    "  \"description\": \"3GPP Dense urban with macro and micro cells\",\n",
    "  \"deploymentScenario\": \"dense_urban\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"two_layer\",\n",
    "  \"isd\": 200,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"Uniform/macro\",\n",
    "  \"ueSpeed\": 3,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 10,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 20,\n",
    "  \"peakHourMultiplier\": 1.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/urban_macro.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/urban_macro.json\n",
    "    {\n",
    "  \"name\": \"3GPP Urban Macro\",\n",
    "  \"description\": \"3GPP Urban macro deployment scenario with large cells and continuous coverage\",\n",
    "  \"deploymentScenario\": \"urban_macro\",\n",
    "  \n",
    "  \"carrierFrequency\": 2e9,\n",
    "  \"systemBandwidth\": 100e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 500,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 30,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 4096,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 25,\n",
    "  \"peakHourMultiplier\": 1.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/high_speed.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/high_speed.json\n",
    "{\n",
    "  \"name\": \"High Speed\",\n",
    "  \"description\": \"3GPP High speed scenario for railway with linear deployment\",\n",
    "  \"deploymentScenario\": \"high_speed\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"linear_railway\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 2,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"100% of users in train\",\n",
    "  \"ueSpeed\": 500,\n",
    "  \"indoorRatio\": 1.0,\n",
    "  \"trainLength\": 200,\n",
    "  \"trackLength\": 10000,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -95,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 30,\n",
    "  \"peakHourMultiplier\": 1.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/rural.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/rural.json\n",
    "{\n",
    "  \"name\": \"3GPP Rural Macro\",\n",
    "  \"description\": \"3GPP Rural deployment scenario with wide area coverage for high speed vehicles\",\n",
    "  \"deploymentScenario\": \"rural\",\n",
    "  \n",
    "  \"carrierFrequency\": 700e6,\n",
    "  \"systemBandwidth\": 20e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 19,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 100,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 120,\n",
    "  \"indoorRatio\": 0.5,\n",
    "  \"outdoorSpeed\": 120,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 0,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -115,\n",
    "  \"rsrpTargetThreshold\": -105,\n",
    "  \"rsrpMeasurementThreshold\": -120,\n",
    "  \"dropCallThreshold\": 2,\n",
    "  \"latencyThreshold\": 100,\n",
    "  \"cpuThreshold\": 90,\n",
    "  \"prbThreshold\": 90,\n",
    "  \n",
    "  \"trafficLambda\": 10,\n",
    "  \"peakHourMultiplier\": 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "training_mode: True\n",
    "use_gpu: False\n",
    "\n",
    "checkpoint_load_path: \"models/zero.pth\"\n",
    "checkpoint_save_path: \"models/um_run1.pth\"\n",
    "\n",
    "actor_lr: 0.0001\n",
    "critic_lr: 0.0003\n",
    "\n",
    "energy_reward_scale: 10.0\n",
    "cost_scale: 0.1\n",
    "\n",
    "entropy_coef: 0.005\n",
    "gamma: 0.99\n",
    "lambda_gae: 0.95\n",
    "clip_epsilon: 0.2\n",
    "ppo_epochs: 4\n",
    "batch_size: 1\n",
    "buffer_size: 4\n",
    "n_envs: 4\n",
    "hidden_dim: 256\n",
    "\n",
    "# Lagrangian PPO settings\n",
    "lambda_init: 0.0\n",
    "lambda_lr: 0.01\n",
    "lambda_max: 100.0\n",
    "# Target average cost per step (set per-scenario scale). 0 encourages constraint satisfaction.\n",
    "cost_target: 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huy/anaconda3/envs/mira/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\n",
      "=== Running Benchmark Suite (4 scenarios) ===\n",
      "Scenarios directory: app/train_scenarios/\n",
      "Using 4 parallel environments per scenario\n",
      "Loaded scenarios: ['dense_urban', 'high_speed', 'rural', 'urban_macro']\n",
      "\n",
      "\n",
      "--- Scenario 1/4: dense_urban ---\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Created 4 parallel environments\n",
      "  Scenario: dense_urban\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: Dense Urban\n",
      "Skipping scenario dense_urban: simTime=0\n",
      "Loaded scenario: Dense Urban\n",
      "\n",
      "Results for dense_urban:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 2/4: high_speed ---\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Created 4 parallel environments\n",
      "  Scenario: high_speed\n",
      "  Action dim: 14\n",
      "  Obs dim: 196\n",
      "Loaded scenario: High Speed\n",
      "Skipping scenario high_speed: simTime=0\n",
      "Loaded scenario: High Speed\n",
      "\n",
      "Results for high_speed:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 3/4: rural ---\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: rural\n",
      "  Action dim: 57\n",
      "  Obs dim: 712\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Skipping scenario rural: simTime=0\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "\n",
      "Results for rural:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 4/4: urban_macro ---\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: urban_macro\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "2025-11-03 23:06:19,545 - PPOAgent - INFO - PPO Agent initialized: 21 cells, 300 UEs\n",
      "2025-11-03 23:06:19,545 - PPOAgent - INFO - State dim: 817, Action dim: 100\n",
      "2025-11-03 23:06:19,545 - PPOAgent - INFO - Device: cpu\n",
      "2025-11-03 23:06:19,546 - PPOAgent - INFO - No checkpoint found at models/zero.pth\n",
      "Created 7 sites for urban_macro scenarioCreated 7 sites for urban_macro scenario\n",
      "\n",
      "Configuring cells for urban_macro scenario...Configuring cells for urban_macro scenario...\n",
      "\n",
      "Configured 21 cells for urban_macro scenario\n",
      "Configured 21 cells for urban_macro scenario\n",
      "Created 7 sites for urban_macro scenarioCreated 7 sites for urban_macro scenario\n",
      "\n",
      "Configuring cells for urban_macro scenario...Configuring cells for urban_macro scenario...\n",
      "\n",
      "Configured 21 cells for urban_macro scenarioConfigured 21 cells for urban_macro scenario\n",
      "\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "===================Starting scenario===================\n",
      "2025-11-03 23:06:30,838 - PPOAgent - INFO - Starting episode: 1\n",
      "Training with 4 parallel environments...\n",
      "Total steps: 4096\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "Warmup episode, returning fixed action\n",
      "2025-11-03 23:06:43,711 - PPOAgent - INFO - Train: J_r=1.0000, J_c=0.0000, Lambda=0.0000, Actor Loss=-0.0000, Critic Loss=0.2976, Cost Critic Loss=2851.2400, Entropy=0.0000\n",
      "2025-11-03 23:06:43,711 - PPOAgent - INFO - Starting episode: 2\n",
      "2025-11-03 23:06:53,561 - PPOAgent - INFO - Train: J_r=-1.0000, J_c=0.7118, Lambda=0.0071, Actor Loss=-1.3964, Critic Loss=0.0081, Cost Critic Loss=0.0285, Entropy=0.0000\n",
      "2025-11-03 23:06:53,562 - PPOAgent - INFO - Starting episode: 3\n",
      "2025-11-03 23:07:03,403 - PPOAgent - INFO - Train: J_r=100.0000, J_c=0.7118, Lambda=0.0142, Actor Loss=0.7288, Critic Loss=9562.8848, Cost Critic Loss=0.0260, Entropy=0.0000\n",
      "2025-11-03 23:07:03,403 - PPOAgent - INFO - Starting episode: 4\n",
      "2025-11-03 23:07:14,539 - PPOAgent - INFO - Train: J_r=68.0260, J_c=0.1988, Lambda=0.0162, Actor Loss=-0.6094, Critic Loss=9380.7100, Cost Critic Loss=0.0205, Entropy=0.8960\n",
      "2025-11-03 23:07:14,539 - PPOAgent - INFO - Starting episode: 5\n",
      "2025-11-03 23:07:25,968 - PPOAgent - INFO - Train: J_r=-100.0000, J_c=0.2584, Lambda=0.0188, Actor Loss=-0.0433, Critic Loss=9655.7598, Cost Critic Loss=0.0001, Entropy=0.8425\n",
      "2025-11-03 23:07:25,969 - PPOAgent - INFO - Starting episode: 6\n",
      "2025-11-03 23:07:37,517 - PPOAgent - INFO - Train: J_r=-100.0000, J_c=0.1683, Lambda=0.0205, Actor Loss=-0.9437, Critic Loss=9339.3701, Cost Critic Loss=0.0000, Entropy=0.8375\n",
      "2025-11-03 23:07:37,518 - PPOAgent - INFO - Starting episode: 7\n",
      "2025-11-03 23:07:48,576 - PPOAgent - INFO - Train: J_r=1.3947, J_c=0.2610, Lambda=0.0231, Actor Loss=0.7591, Critic Loss=9872.5127, Cost Critic Loss=0.0021, Entropy=0.8329\n",
      "2025-11-03 23:07:48,576 - PPOAgent - INFO - Starting episode: 8\n",
      "2025-11-03 23:08:00,545 - PPOAgent - INFO - Train: J_r=71.1233, J_c=0.1873, Lambda=0.0250, Actor Loss=-0.6758, Critic Loss=9861.5889, Cost Critic Loss=0.0084, Entropy=0.7694\n",
      "2025-11-03 23:08:00,545 - PPOAgent - INFO - Starting episode: 9\n",
      "2025-11-03 23:08:11,752 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.1917, Lambda=0.0269, Actor Loss=0.3972, Critic Loss=9934.2168, Cost Critic Loss=0.0002, Entropy=0.7102\n",
      "2025-11-03 23:08:11,752 - PPOAgent - INFO - Starting episode: 10\n",
      "2025-11-03 23:08:23,195 - PPOAgent - INFO - Train: J_r=-70.9802, J_c=0.2037, Lambda=0.0289, Actor Loss=0.4072, Critic Loss=9766.1934, Cost Critic Loss=0.0000, Entropy=0.7091\n",
      "2025-11-03 23:08:23,196 - PPOAgent - INFO - Starting episode: 11\n",
      "2025-11-03 23:08:34,235 - PPOAgent - INFO - Train: J_r=59.3961, J_c=0.2743, Lambda=0.0317, Actor Loss=-0.6005, Critic Loss=9943.7344, Cost Critic Loss=0.0445, Entropy=0.7301\n",
      "2025-11-03 23:08:34,235 - PPOAgent - INFO - Starting episode: 12\n",
      "2025-11-03 23:08:45,649 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.2215, Lambda=0.0339, Actor Loss=-1.0257, Critic Loss=9903.1045, Cost Critic Loss=0.0821, Entropy=0.7465\n",
      "2025-11-03 23:08:45,650 - PPOAgent - INFO - Starting episode: 13\n",
      "2025-11-03 23:08:56,913 - PPOAgent - INFO - Train: J_r=-3.8615, J_c=0.2616, Lambda=0.0365, Actor Loss=0.6505, Critic Loss=10002.9834, Cost Critic Loss=0.0054, Entropy=0.7820\n",
      "2025-11-03 23:08:56,913 - PPOAgent - INFO - Starting episode: 14\n",
      "2025-11-03 23:09:08,164 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.2566, Lambda=0.0391, Actor Loss=0.4007, Critic Loss=9877.8037, Cost Critic Loss=0.0081, Entropy=0.8275\n",
      "2025-11-03 23:09:08,165 - PPOAgent - INFO - Starting episode: 15\n",
      "2025-11-03 23:09:19,350 - PPOAgent - INFO - Train: J_r=79.6188, J_c=0.3102, Lambda=0.0422, Actor Loss=0.4329, Critic Loss=4389.8320, Cost Critic Loss=0.0003, Entropy=0.8142\n",
      "2025-11-03 23:09:19,351 - PPOAgent - INFO - Starting episode: 16\n",
      "2025-11-03 23:09:30,365 - PPOAgent - INFO - Train: J_r=36.3136, J_c=0.2833, Lambda=0.0450, Actor Loss=-0.9109, Critic Loss=9806.0371, Cost Critic Loss=0.0023, Entropy=0.7673\n",
      "2025-11-03 23:09:30,365 - PPOAgent - INFO - Starting episode: 17\n",
      "2025-11-03 23:09:41,647 - PPOAgent - INFO - Train: J_r=36.3666, J_c=0.2334, Lambda=0.0473, Actor Loss=-1.2660, Critic Loss=9713.9570, Cost Critic Loss=0.0001, Entropy=0.5654\n",
      "2025-11-03 23:09:41,647 - PPOAgent - INFO - Starting episode: 18\n",
      "2025-11-03 23:09:53,101 - PPOAgent - INFO - Train: J_r=-89.9730, J_c=0.1725, Lambda=0.0491, Actor Loss=0.6484, Critic Loss=9718.4346, Cost Critic Loss=0.0103, Entropy=0.6446\n",
      "2025-11-03 23:09:53,101 - PPOAgent - INFO - Starting episode: 19\n",
      "2025-11-03 23:10:04,336 - PPOAgent - INFO - Train: J_r=13.7326, J_c=0.2518, Lambda=0.0516, Actor Loss=-0.6909, Critic Loss=10137.5273, Cost Critic Loss=0.0257, Entropy=0.7110\n",
      "2025-11-03 23:10:04,336 - PPOAgent - INFO - Starting episode: 20\n",
      "2025-11-03 23:10:15,389 - PPOAgent - INFO - Train: J_r=5.4759, J_c=0.2961, Lambda=0.0545, Actor Loss=-0.9747, Critic Loss=10030.4199, Cost Critic Loss=0.0507, Entropy=0.5775\n",
      "2025-11-03 23:10:15,389 - PPOAgent - INFO - Starting episode: 21\n",
      "2025-11-03 23:10:26,486 - PPOAgent - INFO - Train: J_r=37.4676, J_c=0.3134, Lambda=0.0577, Actor Loss=-0.8899, Critic Loss=9893.4219, Cost Critic Loss=0.0114, Entropy=0.6489\n",
      "2025-11-03 23:10:26,486 - PPOAgent - INFO - Starting episode: 22\n",
      "2025-11-03 23:10:37,611 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.2515, Lambda=0.0602, Actor Loss=0.4273, Critic Loss=9961.6855, Cost Critic Loss=0.0000, Entropy=0.5613\n",
      "2025-11-03 23:10:37,612 - PPOAgent - INFO - Starting episode: 23\n",
      "2025-11-03 23:10:48,679 - PPOAgent - INFO - Train: J_r=29.5907, J_c=0.3048, Lambda=0.0632, Actor Loss=0.9808, Critic Loss=3782.5156, Cost Critic Loss=0.1256, Entropy=0.6940\n",
      "2025-11-03 23:10:48,679 - PPOAgent - INFO - Starting episode: 24\n",
      "2025-11-03 23:10:59,705 - PPOAgent - INFO - Train: J_r=-17.2494, J_c=0.3218, Lambda=0.0665, Actor Loss=0.6303, Critic Loss=9994.9375, Cost Critic Loss=0.0030, Entropy=0.6346\n",
      "2025-11-03 23:10:59,705 - PPOAgent - INFO - Starting episode: 25\n",
      "2025-11-03 23:11:10,747 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3784, Lambda=0.0702, Actor Loss=-0.8261, Critic Loss=9906.6396, Cost Critic Loss=0.0142, Entropy=0.4108\n",
      "2025-11-03 23:11:10,747 - PPOAgent - INFO - Starting episode: 26\n",
      "2025-11-03 23:11:21,955 - PPOAgent - INFO - Train: J_r=-43.6816, J_c=0.3015, Lambda=0.0733, Actor Loss=0.5158, Critic Loss=9278.9678, Cost Critic Loss=0.0001, Entropy=0.6113\n",
      "2025-11-03 23:11:21,956 - PPOAgent - INFO - Starting episode: 27\n",
      "2025-11-03 23:11:33,142 - PPOAgent - INFO - Train: J_r=-35.2583, J_c=0.2889, Lambda=0.0761, Actor Loss=0.5745, Critic Loss=9864.1621, Cost Critic Loss=0.0468, Entropy=0.5192\n",
      "2025-11-03 23:11:33,142 - PPOAgent - INFO - Starting episode: 28\n",
      "2025-11-03 23:11:44,381 - PPOAgent - INFO - Train: J_r=33.1871, J_c=0.2882, Lambda=0.0790, Actor Loss=1.0466, Critic Loss=10081.8008, Cost Critic Loss=0.0382, Entropy=0.5158\n",
      "2025-11-03 23:11:44,381 - PPOAgent - INFO - Starting episode: 29\n",
      "2025-11-03 23:11:55,617 - PPOAgent - INFO - Train: J_r=-46.1992, J_c=0.2582, Lambda=0.0816, Actor Loss=0.5281, Critic Loss=7110.6680, Cost Critic Loss=0.0142, Entropy=0.3502\n",
      "2025-11-03 23:11:55,617 - PPOAgent - INFO - Starting episode: 30\n",
      "2025-11-03 23:12:06,753 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3081, Lambda=0.0847, Actor Loss=1.2085, Critic Loss=10042.2002, Cost Critic Loss=0.0241, Entropy=0.1768\n",
      "2025-11-03 23:12:06,754 - PPOAgent - INFO - Starting episode: 31\n",
      "2025-11-03 23:12:17,903 - PPOAgent - INFO - Train: J_r=-39.3038, J_c=0.2720, Lambda=0.0874, Actor Loss=-1.1931, Critic Loss=4738.1060, Cost Critic Loss=0.0017, Entropy=0.1893\n",
      "2025-11-03 23:12:17,903 - PPOAgent - INFO - Starting episode: 32\n",
      "2025-11-03 23:12:28,983 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3154, Lambda=0.0906, Actor Loss=-0.4803, Critic Loss=9954.5596, Cost Critic Loss=0.0222, Entropy=-0.0479\n",
      "2025-11-03 23:12:28,983 - PPOAgent - INFO - Starting episode: 33\n",
      "2025-11-03 23:12:40,021 - PPOAgent - INFO - Train: J_r=8.6874, J_c=0.3473, Lambda=0.0940, Actor Loss=-1.5390, Critic Loss=9956.6768, Cost Critic Loss=0.0099, Entropy=0.0880\n",
      "2025-11-03 23:12:40,021 - PPOAgent - INFO - Starting episode: 34\n",
      "2025-11-03 23:12:51,156 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.2542, Lambda=0.0966, Actor Loss=0.7233, Critic Loss=10009.8369, Cost Critic Loss=0.0000, Entropy=0.0855\n",
      "2025-11-03 23:12:51,157 - PPOAgent - INFO - Starting episode: 35\n",
      "2025-11-03 23:13:02,195 - PPOAgent - INFO - Train: J_r=-5.9684, J_c=0.3386, Lambda=0.1000, Actor Loss=0.7011, Critic Loss=10004.6182, Cost Critic Loss=0.0580, Entropy=0.3965\n",
      "2025-11-03 23:13:02,195 - PPOAgent - INFO - Starting episode: 36\n",
      "2025-11-03 23:13:13,419 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.2417, Lambda=0.1024, Actor Loss=0.4051, Critic Loss=9942.7119, Cost Critic Loss=0.0180, Entropy=0.2314\n",
      "2025-11-03 23:13:13,419 - PPOAgent - INFO - Starting episode: 37\n",
      "Energy Delta=-1.1543, Total Traffic Demand=47.0000, Reward=2.4560\n",
      "2025-11-03 23:13:24,397 - PPOAgent - INFO - Train: J_r=40.6828, J_c=0.3420, Lambda=0.1058, Actor Loss=-0.8947, Critic Loss=9982.9678, Cost Critic Loss=0.2821, Entropy=0.2063\n",
      "2025-11-03 23:13:24,397 - PPOAgent - INFO - Starting episode: 38\n",
      "2025-11-03 23:13:35,397 - PPOAgent - INFO - Train: J_r=13.5418, J_c=0.3514, Lambda=0.1093, Actor Loss=-1.5055, Critic Loss=2717.4653, Cost Critic Loss=0.0159, Entropy=0.0971\n",
      "2025-11-03 23:13:35,397 - PPOAgent - INFO - Starting episode: 39\n",
      "2025-11-03 23:13:46,440 - PPOAgent - INFO - Train: J_r=-30.1373, J_c=0.3269, Lambda=0.1126, Actor Loss=-1.5797, Critic Loss=10062.7021, Cost Critic Loss=0.0982, Entropy=0.2374\n",
      "2025-11-03 23:13:46,441 - PPOAgent - INFO - Starting episode: 40\n",
      "2025-11-03 23:13:57,482 - PPOAgent - INFO - Train: J_r=-33.4482, J_c=0.3034, Lambda=0.1156, Actor Loss=0.5291, Critic Loss=9831.1416, Cost Critic Loss=0.0434, Entropy=0.4441\n",
      "2025-11-03 23:13:57,482 - PPOAgent - INFO - Starting episode: 41\n",
      "2025-11-03 23:14:08,350 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.4000, Lambda=0.1196, Actor Loss=-1.1696, Critic Loss=10114.9443, Cost Critic Loss=0.0147, Entropy=0.2126\n",
      "2025-11-03 23:14:08,351 - PPOAgent - INFO - Starting episode: 42\n",
      "2025-11-03 23:14:19,183 - PPOAgent - INFO - Train: J_r=-18.1105, J_c=0.3890, Lambda=0.1235, Actor Loss=0.2049, Critic Loss=742.0359, Cost Critic Loss=0.1253, Entropy=0.4630\n",
      "2025-11-03 23:14:19,183 - PPOAgent - INFO - Starting episode: 43\n",
      "2025-11-03 23:14:30,209 - PPOAgent - INFO - Train: J_r=7.6674, J_c=0.3115, Lambda=0.1266, Actor Loss=-1.2704, Critic Loss=10170.6270, Cost Critic Loss=0.0260, Entropy=0.7268\n",
      "2025-11-03 23:14:30,210 - PPOAgent - INFO - Starting episode: 44\n",
      "2025-11-03 23:14:40,901 - PPOAgent - INFO - Train: J_r=27.6542, J_c=0.4007, Lambda=0.1306, Actor Loss=-0.8099, Critic Loss=10039.9053, Cost Critic Loss=0.0038, Entropy=0.6244\n",
      "2025-11-03 23:14:40,902 - PPOAgent - INFO - Starting episode: 45\n",
      "2025-11-03 23:14:51,827 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.3773, Lambda=0.1344, Actor Loss=0.4137, Critic Loss=9717.9580, Cost Critic Loss=0.1686, Entropy=0.4149\n",
      "2025-11-03 23:14:51,827 - PPOAgent - INFO - Starting episode: 46\n",
      "2025-11-03 23:15:02,577 - PPOAgent - INFO - Train: J_r=-17.8275, J_c=0.4320, Lambda=0.1387, Actor Loss=-0.4523, Critic Loss=899.6816, Cost Critic Loss=0.0028, Entropy=0.4922\n",
      "2025-11-03 23:15:02,578 - PPOAgent - INFO - Starting episode: 47\n",
      "2025-11-03 23:15:13,423 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3971, Lambda=0.1427, Actor Loss=-0.5023, Critic Loss=9772.9180, Cost Critic Loss=0.0708, Entropy=0.6501\n",
      "2025-11-03 23:15:13,423 - PPOAgent - INFO - Starting episode: 48\n",
      "2025-11-03 23:15:24,095 - PPOAgent - INFO - Train: J_r=3.9394, J_c=0.3846, Lambda=0.1465, Actor Loss=-1.1407, Critic Loss=3614.2881, Cost Critic Loss=0.0447, Entropy=0.4468\n",
      "2025-11-03 23:15:24,095 - PPOAgent - INFO - Starting episode: 49\n",
      "Step 50/4096: Energy: 0.345 kWh, Power: 25.3 kW, Drop Rate: 4.86%\n",
      "Drop rate violation: 4.86% > 1%\n",
      "Step 50/4096: Energy: 0.345 kWh, Power: 25.4 kW, Drop Rate: 6.01%\n",
      "Drop rate violation: 6.01% > 1%\n",
      "Step 50/4096: Energy: 0.345 kWh, Power: 25.5 kW, Drop Rate: 4.68%\n",
      "Drop rate violation: 4.68% > 1%\n",
      "Step 50/4096: Energy: 0.345 kWh, Power: 25.4 kW, Drop Rate: 4.27%\n",
      "Drop rate violation: 4.27% > 1%\n",
      "2025-11-03 23:15:34,973 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.3956, Lambda=0.1505, Actor Loss=-2.0500, Critic Loss=10221.2773, Cost Critic Loss=0.0356, Entropy=0.2654\n",
      "2025-11-03 23:15:34,973 - PPOAgent - INFO - Starting episode: 50\n",
      "2025-11-03 23:15:45,865 - PPOAgent - INFO - Train: J_r=-1.0661, J_c=0.3762, Lambda=0.1543, Actor Loss=0.7039, Critic Loss=9826.6172, Cost Critic Loss=0.2245, Entropy=0.5124\n",
      "2025-11-03 23:15:45,865 - PPOAgent - INFO - Starting episode: 51\n",
      "2025-11-03 23:15:56,637 - PPOAgent - INFO - Train: J_r=4.3945, J_c=0.4078, Lambda=0.1583, Actor Loss=-1.4670, Critic Loss=10062.1992, Cost Critic Loss=0.0646, Entropy=0.3645\n",
      "2025-11-03 23:15:56,638 - PPOAgent - INFO - Starting episode: 52\n",
      "2025-11-03 23:16:07,442 - PPOAgent - INFO - Train: J_r=41.1291, J_c=0.3536, Lambda=0.1619, Actor Loss=-0.5566, Critic Loss=9675.1299, Cost Critic Loss=0.0071, Entropy=0.2214\n",
      "2025-11-03 23:16:07,442 - PPOAgent - INFO - Starting episode: 53\n",
      "2025-11-03 23:16:18,348 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3059, Lambda=0.1649, Actor Loss=-1.5657, Critic Loss=9487.0781, Cost Critic Loss=0.0154, Entropy=0.3232\n",
      "2025-11-03 23:16:18,348 - PPOAgent - INFO - Starting episode: 54\n",
      "2025-11-03 23:16:29,347 - PPOAgent - INFO - Train: J_r=17.2298, J_c=0.3433, Lambda=0.1684, Actor Loss=0.9665, Critic Loss=10255.8164, Cost Critic Loss=0.0048, Entropy=0.5335\n",
      "2025-11-03 23:16:29,347 - PPOAgent - INFO - Starting episode: 55\n",
      "2025-11-03 23:16:40,003 - PPOAgent - INFO - Train: J_r=47.8247, J_c=0.4375, Lambda=0.1727, Actor Loss=1.0632, Critic Loss=10284.3047, Cost Critic Loss=0.0028, Entropy=0.3343\n",
      "2025-11-03 23:16:40,003 - PPOAgent - INFO - Starting episode: 56\n",
      "2025-11-03 23:16:50,758 - PPOAgent - INFO - Train: J_r=-21.7451, J_c=0.3624, Lambda=0.1764, Actor Loss=0.4369, Critic Loss=10081.1406, Cost Critic Loss=0.1087, Entropy=0.4389\n",
      "2025-11-03 23:16:50,758 - PPOAgent - INFO - Starting episode: 57\n",
      "2025-11-03 23:17:01,725 - PPOAgent - INFO - Train: J_r=-64.0830, J_c=0.3718, Lambda=0.1801, Actor Loss=-1.3045, Critic Loss=730.4218, Cost Critic Loss=0.0062, Entropy=0.5279\n",
      "2025-11-03 23:17:01,726 - PPOAgent - INFO - Starting episode: 58\n",
      "2025-11-03 23:17:12,780 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.3265, Lambda=0.1833, Actor Loss=-1.4362, Critic Loss=10067.2119, Cost Critic Loss=0.0057, Entropy=0.6094\n",
      "2025-11-03 23:17:12,781 - PPOAgent - INFO - Starting episode: 59\n",
      "2025-11-03 23:17:23,942 - PPOAgent - INFO - Train: J_r=-26.0967, J_c=0.3162, Lambda=0.1865, Actor Loss=0.5752, Critic Loss=9915.0312, Cost Critic Loss=0.0303, Entropy=0.4638\n",
      "2025-11-03 23:17:23,942 - PPOAgent - INFO - Starting episode: 60\n",
      "2025-11-03 23:17:35,033 - PPOAgent - INFO - Train: J_r=-30.6109, J_c=0.3259, Lambda=0.1898, Actor Loss=0.6442, Critic Loss=9832.2949, Cost Critic Loss=0.0000, Entropy=0.4496\n",
      "2025-11-03 23:17:35,033 - PPOAgent - INFO - Starting episode: 61\n",
      "2025-11-03 23:17:45,768 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3806, Lambda=0.1936, Actor Loss=-0.4955, Critic Loss=9973.2080, Cost Critic Loss=0.0594, Entropy=0.4576\n",
      "2025-11-03 23:17:45,768 - PPOAgent - INFO - Starting episode: 62\n",
      "2025-11-03 23:17:56,842 - PPOAgent - INFO - Train: J_r=20.5596, J_c=0.3191, Lambda=0.1968, Actor Loss=-0.8783, Critic Loss=9933.4990, Cost Critic Loss=0.0018, Entropy=0.0609\n",
      "2025-11-03 23:17:56,842 - PPOAgent - INFO - Starting episode: 63\n",
      "2025-11-03 23:18:07,586 - PPOAgent - INFO - Train: J_r=100.0000, J_c=0.3994, Lambda=0.2008, Actor Loss=0.3845, Critic Loss=9813.4775, Cost Critic Loss=0.0026, Entropy=0.1708\n",
      "2025-11-03 23:18:07,586 - PPOAgent - INFO - Starting episode: 64\n",
      "2025-11-03 23:18:18,506 - PPOAgent - INFO - Train: J_r=-55.1667, J_c=0.3961, Lambda=0.2047, Actor Loss=-2.3595, Critic Loss=321.2197, Cost Critic Loss=0.0564, Entropy=0.2850\n",
      "2025-11-03 23:18:18,506 - PPOAgent - INFO - Starting episode: 65\n",
      "Energy Delta=70.6992, Total Traffic Demand=31.0000, Reward=-100.0000\n",
      "2025-11-03 23:18:29,417 - PPOAgent - INFO - Train: J_r=-26.0895, J_c=0.3579, Lambda=0.2083, Actor Loss=0.6599, Critic Loss=9858.5889, Cost Critic Loss=0.3204, Entropy=0.2373\n",
      "2025-11-03 23:18:29,417 - PPOAgent - INFO - Starting episode: 66\n",
      "2025-11-03 23:18:40,470 - PPOAgent - INFO - Train: J_r=-36.7364, J_c=0.3167, Lambda=0.2115, Actor Loss=0.1004, Critic Loss=2124.8638, Cost Critic Loss=0.0330, Entropy=-0.0872\n",
      "2025-11-03 23:18:40,470 - PPOAgent - INFO - Starting episode: 67\n",
      "2025-11-03 23:18:51,611 - PPOAgent - INFO - Train: J_r=-58.0627, J_c=0.3105, Lambda=0.2146, Actor Loss=-0.6936, Critic Loss=4788.6626, Cost Critic Loss=0.0000, Entropy=0.1736\n",
      "2025-11-03 23:18:51,611 - PPOAgent - INFO - Starting episode: 68\n",
      "2025-11-03 23:19:02,499 - PPOAgent - INFO - Train: J_r=30.1043, J_c=0.3871, Lambda=0.2184, Actor Loss=-1.0649, Critic Loss=411.9376, Cost Critic Loss=0.0638, Entropy=0.0825\n",
      "2025-11-03 23:19:02,500 - PPOAgent - INFO - Starting episode: 69\n",
      "2025-11-03 23:19:13,537 - PPOAgent - INFO - Train: J_r=-29.9805, J_c=0.3314, Lambda=0.2218, Actor Loss=0.4471, Critic Loss=9944.1094, Cost Critic Loss=0.0263, Entropy=0.2729\n",
      "2025-11-03 23:19:13,537 - PPOAgent - INFO - Starting episode: 70\n",
      "2025-11-03 23:19:24,200 - PPOAgent - INFO - Train: J_r=42.0568, J_c=0.4347, Lambda=0.2261, Actor Loss=-0.3978, Critic Loss=4629.9590, Cost Critic Loss=0.0268, Entropy=-0.4939\n",
      "2025-11-03 23:19:24,200 - PPOAgent - INFO - Starting episode: 71\n",
      "2025-11-03 23:19:35,160 - PPOAgent - INFO - Train: J_r=-0.6874, J_c=0.3297, Lambda=0.2294, Actor Loss=-1.1008, Critic Loss=9393.8281, Cost Critic Loss=0.0242, Entropy=0.2055\n",
      "2025-11-03 23:19:35,160 - PPOAgent - INFO - Starting episode: 72\n",
      "2025-11-03 23:19:46,225 - PPOAgent - INFO - Train: J_r=-35.2557, J_c=0.3306, Lambda=0.2327, Actor Loss=-1.3738, Critic Loss=8075.4971, Cost Critic Loss=0.0485, Entropy=-0.0522\n",
      "2025-11-03 23:19:46,225 - PPOAgent - INFO - Starting episode: 73\n",
      "2025-11-03 23:19:57,273 - PPOAgent - INFO - Train: J_r=-15.3889, J_c=0.3400, Lambda=0.2361, Actor Loss=-0.4038, Critic Loss=3487.1372, Cost Critic Loss=0.0605, Entropy=-0.0713\n",
      "2025-11-03 23:19:57,273 - PPOAgent - INFO - Starting episode: 74\n",
      "2025-11-03 23:20:08,155 - PPOAgent - INFO - Train: J_r=10.6291, J_c=0.3668, Lambda=0.2398, Actor Loss=-0.7141, Critic Loss=10040.5146, Cost Critic Loss=0.0070, Entropy=0.0215\n",
      "2025-11-03 23:20:08,155 - PPOAgent - INFO - Starting episode: 75\n",
      "2025-11-03 23:20:19,187 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.3338, Lambda=0.2431, Actor Loss=1.2991, Critic Loss=10158.9932, Cost Critic Loss=0.1393, Entropy=0.1241\n",
      "2025-11-03 23:20:19,187 - PPOAgent - INFO - Starting episode: 76\n",
      "2025-11-03 23:20:30,184 - PPOAgent - INFO - Train: J_r=0.1276, J_c=0.3785, Lambda=0.2469, Actor Loss=-0.2897, Critic Loss=9919.5605, Cost Critic Loss=0.0217, Entropy=-0.1645\n",
      "2025-11-03 23:20:30,184 - PPOAgent - INFO - Starting episode: 77\n",
      "2025-11-03 23:20:41,067 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.3775, Lambda=0.2507, Actor Loss=0.4043, Critic Loss=9889.1064, Cost Critic Loss=0.0849, Entropy=-0.0670\n",
      "2025-11-03 23:20:41,067 - PPOAgent - INFO - Starting episode: 78\n",
      "2025-11-03 23:20:51,925 - PPOAgent - INFO - Train: J_r=-2.3955, J_c=0.3668, Lambda=0.2543, Actor Loss=0.4751, Critic Loss=9889.9180, Cost Critic Loss=0.0003, Entropy=0.0925\n",
      "2025-11-03 23:20:51,925 - PPOAgent - INFO - Starting episode: 79\n",
      "2025-11-03 23:21:02,946 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.3518, Lambda=0.2579, Actor Loss=0.7458, Critic Loss=9986.8203, Cost Critic Loss=0.0654, Entropy=-0.0602\n",
      "2025-11-03 23:21:02,946 - PPOAgent - INFO - Starting episode: 80\n",
      "2025-11-03 23:21:14,091 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.2842, Lambda=0.2607, Actor Loss=-1.0361, Critic Loss=10039.4277, Cost Critic Loss=0.0418, Entropy=-0.4570\n",
      "2025-11-03 23:21:14,091 - PPOAgent - INFO - Starting episode: 81\n",
      "2025-11-03 23:21:24,819 - PPOAgent - INFO - Train: J_r=-51.2328, J_c=0.3644, Lambda=0.2643, Actor Loss=0.5606, Critic Loss=9824.7549, Cost Critic Loss=0.3617, Entropy=-0.0768\n",
      "2025-11-03 23:21:24,820 - PPOAgent - INFO - Starting episode: 82\n",
      "2025-11-03 23:21:35,682 - PPOAgent - INFO - Train: J_r=48.0685, J_c=0.3981, Lambda=0.2683, Actor Loss=-0.6610, Critic Loss=9950.4199, Cost Critic Loss=0.0042, Entropy=0.0657\n",
      "2025-11-03 23:21:35,682 - PPOAgent - INFO - Starting episode: 83\n",
      "2025-11-03 23:21:46,592 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.3533, Lambda=0.2719, Actor Loss=-1.0344, Critic Loss=9924.7178, Cost Critic Loss=0.0539, Entropy=-0.2878\n",
      "2025-11-03 23:21:46,592 - PPOAgent - INFO - Starting episode: 84\n",
      "2025-11-03 23:21:57,122 - PPOAgent - INFO - Train: J_r=-1.7316, J_c=0.4368, Lambda=0.2762, Actor Loss=-1.7943, Critic Loss=9999.1318, Cost Critic Loss=0.0733, Entropy=-0.4020\n",
      "2025-11-03 23:21:57,122 - PPOAgent - INFO - Starting episode: 85\n",
      "2025-11-03 23:22:07,913 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.3947, Lambda=0.2802, Actor Loss=0.4407, Critic Loss=9832.8105, Cost Critic Loss=0.0076, Entropy=-0.2679\n",
      "2025-11-03 23:22:07,914 - PPOAgent - INFO - Starting episode: 86\n",
      "Drop=4.7390%, Latency=34.0232ms, CPU=95.0000%, PRB=95.0000%\n",
      "QoS Cost: 0.3739\n",
      "Drop Violation=3.7390, Latency Violation=0.0000, CPU Violation=0.0000, PRB Violation=0.0000\n",
      "2025-11-03 23:22:18,851 - PPOAgent - INFO - Train: J_r=-7.9301, J_c=0.3755, Lambda=0.2839, Actor Loss=0.7195, Critic Loss=9879.8477, Cost Critic Loss=0.0164, Entropy=-0.2869\n",
      "2025-11-03 23:22:18,851 - PPOAgent - INFO - Starting episode: 87\n",
      "2025-11-03 23:22:29,739 - PPOAgent - INFO - Train: J_r=11.6008, J_c=0.3846, Lambda=0.2878, Actor Loss=0.5011, Critic Loss=2523.2161, Cost Critic Loss=0.0029, Entropy=-0.5928\n",
      "2025-11-03 23:22:29,739 - PPOAgent - INFO - Starting episode: 88\n",
      "2025-11-03 23:22:40,412 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.4391, Lambda=0.2922, Actor Loss=-0.4567, Critic Loss=10038.5518, Cost Critic Loss=0.0025, Entropy=-0.4653\n",
      "2025-11-03 23:22:40,412 - PPOAgent - INFO - Starting episode: 89\n",
      "2025-11-03 23:22:51,080 - PPOAgent - INFO - Train: J_r=33.9693, J_c=0.3688, Lambda=0.2958, Actor Loss=-2.1462, Critic Loss=9835.4424, Cost Critic Loss=0.0041, Entropy=0.0813\n",
      "2025-11-03 23:22:51,080 - PPOAgent - INFO - Starting episode: 90\n",
      "2025-11-03 23:23:01,924 - PPOAgent - INFO - Train: J_r=-13.2563, J_c=0.3630, Lambda=0.2995, Actor Loss=0.4913, Critic Loss=10133.8740, Cost Critic Loss=0.0250, Entropy=-0.2823\n",
      "2025-11-03 23:23:01,924 - PPOAgent - INFO - Starting episode: 91\n",
      "2025-11-03 23:23:12,649 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.4296, Lambda=0.3038, Actor Loss=-0.8360, Critic Loss=9838.2070, Cost Critic Loss=0.0219, Entropy=-0.5341\n",
      "2025-11-03 23:23:12,650 - PPOAgent - INFO - Starting episode: 92\n",
      "2025-11-03 23:23:23,351 - PPOAgent - INFO - Train: J_r=76.6882, J_c=0.4269, Lambda=0.3080, Actor Loss=0.1848, Critic Loss=3798.9375, Cost Critic Loss=0.0409, Entropy=-0.3817\n",
      "2025-11-03 23:23:23,351 - PPOAgent - INFO - Starting episode: 93\n",
      "2025-11-03 23:23:34,114 - PPOAgent - INFO - Train: J_r=-13.0025, J_c=0.4047, Lambda=0.3121, Actor Loss=0.5320, Critic Loss=10246.5391, Cost Critic Loss=0.0409, Entropy=-0.3480\n",
      "2025-11-03 23:23:34,114 - PPOAgent - INFO - Starting episode: 94\n",
      "2025-11-03 23:23:44,990 - PPOAgent - INFO - Train: J_r=-100.0000, J_c=0.3769, Lambda=0.3159, Actor Loss=-0.5368, Critic Loss=9573.3252, Cost Critic Loss=0.0299, Entropy=-0.1284\n",
      "2025-11-03 23:23:44,990 - PPOAgent - INFO - Starting episode: 95\n",
      "2025-11-03 23:23:55,770 - PPOAgent - INFO - Train: J_r=78.8539, J_c=0.4455, Lambda=0.3203, Actor Loss=-0.0170, Critic Loss=6945.7417, Cost Critic Loss=0.0011, Entropy=-0.5450\n",
      "2025-11-03 23:23:55,771 - PPOAgent - INFO - Starting episode: 96\n",
      "2025-11-03 23:24:06,509 - PPOAgent - INFO - Train: J_r=19.4913, J_c=0.4580, Lambda=0.3249, Actor Loss=0.3772, Critic Loss=549.2925, Cost Critic Loss=0.0027, Entropy=-0.2035\n",
      "2025-11-03 23:24:06,509 - PPOAgent - INFO - Starting episode: 97\n",
      "2025-11-03 23:24:17,247 - PPOAgent - INFO - Train: J_r=-36.0529, J_c=0.4493, Lambda=0.3294, Actor Loss=0.5620, Critic Loss=9802.9248, Cost Critic Loss=0.0023, Entropy=-0.7603\n",
      "2025-11-03 23:24:17,248 - PPOAgent - INFO - Starting episode: 98\n",
      "2025-11-03 23:24:28,054 - PPOAgent - INFO - Train: J_r=10.6950, J_c=0.4728, Lambda=0.3341, Actor Loss=-0.6313, Critic Loss=10153.2656, Cost Critic Loss=0.0298, Entropy=-0.7294\n",
      "2025-11-03 23:24:28,054 - PPOAgent - INFO - Starting episode: 99\n",
      "Step 100/4096: Energy: 0.698 kWh, Power: 25.4 kW, Drop Rate: 5.84%\n",
      "Drop rate violation: 5.84% > 1%\n",
      "Step 100/4096: Energy: 0.698 kWh, Power: 25.2 kW, Drop Rate: 5.96%\n",
      "Drop rate violation: 5.96% > 1%\n",
      "Step 100/4096: Energy: 0.698 kWh, Power: 25.4 kW, Drop Rate: 6.44%\n",
      "Drop rate violation: 6.44% > 1%\n",
      "Step 100/4096: Energy: 0.698 kWh, Power: 25.4 kW, Drop Rate: 6.13%\n",
      "Drop rate violation: 6.13% > 1%\n",
      "2025-11-03 23:24:38,725 - PPOAgent - INFO - Train: J_r=-29.3466, J_c=0.5093, Lambda=0.3392, Actor Loss=0.5971, Critic Loss=9780.7529, Cost Critic Loss=0.0008, Entropy=-0.2722\n",
      "2025-11-03 23:24:38,726 - PPOAgent - INFO - Starting episode: 100\n",
      "2025-11-03 23:24:49,431 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.4527, Lambda=0.3437, Actor Loss=1.0959, Critic Loss=9847.9365, Cost Critic Loss=0.0318, Entropy=-0.6265\n",
      "2025-11-03 23:24:49,431 - PPOAgent - INFO - Starting episode: 101\n",
      "  Step 100/4096: 4/4 envs active\n",
      "2025-11-03 23:25:00,079 - PPOAgent - INFO - Train: J_r=-0.9583, J_c=0.4159, Lambda=0.3479, Actor Loss=-0.4451, Critic Loss=1011.0516, Cost Critic Loss=0.0056, Entropy=-0.4596\n",
      "2025-11-03 23:25:00,079 - PPOAgent - INFO - Starting episode: 102\n",
      "2025-11-03 23:25:10,955 - PPOAgent - INFO - Train: J_r=0.0000, J_c=0.3879, Lambda=0.3518, Actor Loss=-3.8773, Critic Loss=10019.1982, Cost Critic Loss=0.3792, Entropy=-0.1177\n",
      "2025-11-03 23:25:10,955 - PPOAgent - INFO - Starting episode: 103\n",
      "Drop=5.2753%, Latency=35.6991ms, CPU=95.0000%, PRB=95.0000%\n",
      "QoS Cost: 0.4275\n",
      "Drop Violation=4.2753, Latency Violation=0.0000, CPU Violation=0.0000, PRB Violation=0.0000\n",
      "2025-11-03 23:25:21,815 - PPOAgent - INFO - Train: J_r=76.4948, J_c=0.4033, Lambda=0.3558, Actor Loss=-1.9434, Critic Loss=9669.9824, Cost Critic Loss=0.0003, Entropy=-0.2891\n",
      "2025-11-03 23:25:21,816 - PPOAgent - INFO - Starting episode: 104\n",
      "2025-11-03 23:25:32,549 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.4540, Lambda=0.3603, Actor Loss=-0.7498, Critic Loss=9777.3594, Cost Critic Loss=0.0503, Entropy=-0.0110\n",
      "2025-11-03 23:25:32,549 - PPOAgent - INFO - Starting episode: 105\n",
      "Energy Delta=27.7891, Total Traffic Demand=38.0000, Reward=-73.1291\n",
      "2025-11-03 23:25:43,278 - PPOAgent - INFO - Train: J_r=-91.6289, J_c=0.4455, Lambda=0.3648, Actor Loss=0.3366, Critic Loss=9836.1279, Cost Critic Loss=0.0205, Entropy=-0.4705\n",
      "2025-11-03 23:25:43,279 - PPOAgent - INFO - Starting episode: 106\n",
      "2025-11-03 23:25:54,151 - PPOAgent - INFO - Train: J_r=-18.7520, J_c=0.4162, Lambda=0.3690, Actor Loss=-0.0578, Critic Loss=2503.4229, Cost Critic Loss=0.0087, Entropy=-0.3544\n",
      "2025-11-03 23:25:54,151 - PPOAgent - INFO - Starting episode: 107\n",
      "2025-11-03 23:26:05,088 - PPOAgent - INFO - Train: J_r=-50.0000, J_c=0.3925, Lambda=0.3729, Actor Loss=0.4074, Critic Loss=9823.5576, Cost Critic Loss=0.0261, Entropy=0.0647\n",
      "2025-11-03 23:26:05,088 - PPOAgent - INFO - Starting episode: 108\n",
      "2025-11-03 23:26:16,118 - PPOAgent - INFO - Train: J_r=37.6049, J_c=0.3606, Lambda=0.3765, Actor Loss=1.2488, Critic Loss=10028.1719, Cost Critic Loss=0.0687, Entropy=-0.3597\n",
      "2025-11-03 23:26:16,118 - PPOAgent - INFO - Starting episode: 109\n",
      "2025-11-03 23:26:27,055 - PPOAgent - INFO - Train: J_r=34.8971, J_c=0.3765, Lambda=0.3803, Actor Loss=-1.8772, Critic Loss=4631.9712, Cost Critic Loss=0.3766, Entropy=-0.2139\n",
      "2025-11-03 23:26:27,056 - PPOAgent - INFO - Starting episode: 110\n",
      "2025-11-03 23:26:37,855 - PPOAgent - INFO - Train: J_r=1.6042, J_c=0.4411, Lambda=0.3847, Actor Loss=0.5011, Critic Loss=8826.6396, Cost Critic Loss=0.3743, Entropy=-0.5475\n",
      "2025-11-03 23:26:37,856 - PPOAgent - INFO - Starting episode: 111\n",
      "2025-11-03 23:26:48,738 - PPOAgent - INFO - Train: J_r=-14.9715, J_c=0.3942, Lambda=0.3886, Actor Loss=-1.3669, Critic Loss=9997.1006, Cost Critic Loss=0.1959, Entropy=-0.4010\n",
      "2025-11-03 23:26:48,739 - PPOAgent - INFO - Starting episode: 112\n",
      "2025-11-03 23:26:59,530 - PPOAgent - INFO - Train: J_r=-18.1319, J_c=0.3975, Lambda=0.3926, Actor Loss=-2.2090, Critic Loss=10001.3457, Cost Critic Loss=0.0013, Entropy=-0.1328\n",
      "2025-11-03 23:26:59,530 - PPOAgent - INFO - Starting episode: 113\n",
      "2025-11-03 23:27:10,251 - PPOAgent - INFO - Train: J_r=57.7447, J_c=0.4501, Lambda=0.3971, Actor Loss=-0.7562, Critic Loss=8577.5195, Cost Critic Loss=0.1359, Entropy=-0.6803\n",
      "2025-11-03 23:27:10,252 - PPOAgent - INFO - Starting episode: 114\n",
      "2025-11-03 23:27:21,178 - PPOAgent - INFO - Train: J_r=-10.9731, J_c=0.3776, Lambda=0.4009, Actor Loss=0.0526, Critic Loss=34.8084, Cost Critic Loss=0.0086, Entropy=0.1080\n",
      "2025-11-03 23:27:21,179 - PPOAgent - INFO - Starting episode: 115\n",
      "2025-11-03 23:27:32,019 - PPOAgent - INFO - Train: J_r=95.0076, J_c=0.4261, Lambda=0.4051, Actor Loss=-0.5938, Critic Loss=9930.7041, Cost Critic Loss=0.0382, Entropy=-0.1350\n",
      "2025-11-03 23:27:32,019 - PPOAgent - INFO - Starting episode: 116\n",
      "2025-11-03 23:27:42,645 - PPOAgent - INFO - Train: J_r=22.5725, J_c=0.4662, Lambda=0.4098, Actor Loss=-2.5694, Critic Loss=9953.0811, Cost Critic Loss=0.1859, Entropy=-0.0620\n",
      "2025-11-03 23:27:42,646 - PPOAgent - INFO - Starting episode: 117\n",
      "2025-11-03 23:27:53,556 - PPOAgent - INFO - Train: J_r=-15.0333, J_c=0.4116, Lambda=0.4139, Actor Loss=0.8007, Critic Loss=10003.9062, Cost Critic Loss=0.0506, Entropy=0.1083\n",
      "2025-11-03 23:27:53,556 - PPOAgent - INFO - Starting episode: 118\n",
      "2025-11-03 23:28:04,441 - PPOAgent - INFO - Train: J_r=-89.1590, J_c=0.4192, Lambda=0.4181, Actor Loss=0.2753, Critic Loss=9889.4570, Cost Critic Loss=0.0007, Entropy=0.0515\n",
      "2025-11-03 23:28:04,441 - PPOAgent - INFO - Starting episode: 119\n",
      "2025-11-03 23:28:15,152 - PPOAgent - INFO - Train: J_r=-28.5529, J_c=0.4732, Lambda=0.4228, Actor Loss=0.9075, Critic Loss=6654.2002, Cost Critic Loss=0.1799, Entropy=-0.6010\n",
      "2025-11-03 23:28:15,153 - PPOAgent - INFO - Starting episode: 120\n",
      "2025-11-03 23:28:25,779 - PPOAgent - INFO - Train: J_r=50.0000, J_c=0.4898, Lambda=0.4277, Actor Loss=-1.4192, Critic Loss=9951.6924, Cost Critic Loss=0.0090, Entropy=-0.2941\n",
      "2025-11-03 23:28:25,779 - PPOAgent - INFO - Starting episode: 121\n",
      "2025-11-03 23:28:36,789 - PPOAgent - INFO - Train: J_r=-7.6554, J_c=0.4514, Lambda=0.4322, Actor Loss=-1.2217, Critic Loss=4447.2695, Cost Critic Loss=0.0022, Entropy=-0.1123\n",
      "2025-11-03 23:28:36,790 - PPOAgent - INFO - Starting episode: 122\n",
      "2025-11-03 23:28:47,432 - PPOAgent - INFO - Train: J_r=18.0130, J_c=0.4544, Lambda=0.4368, Actor Loss=0.6239, Critic Loss=2178.8430, Cost Critic Loss=0.0211, Entropy=-0.2452\n",
      "2025-11-03 23:28:47,432 - PPOAgent - INFO - Starting episode: 123\n",
      "Energy Delta=-61.5605, Total Traffic Demand=25.0000, Reward=100.0000\n",
      "2025-11-03 23:28:58,602 - PPOAgent - INFO - Train: J_r=9.9043, J_c=0.4324, Lambda=0.4411, Actor Loss=0.9332, Critic Loss=9994.6338, Cost Critic Loss=0.0083, Entropy=0.0944\n",
      "2025-11-03 23:28:58,603 - PPOAgent - INFO - Starting episode: 124\n",
      "2025-11-03 23:29:09,816 - PPOAgent - INFO - Train: J_r=2.0934, J_c=0.4456, Lambda=0.4456, Actor Loss=0.4531, Critic Loss=9962.5273, Cost Critic Loss=0.0025, Entropy=-0.4819\n",
      "2025-11-03 23:29:09,817 - PPOAgent - INFO - Starting episode: 125\n",
      "2025-11-03 23:29:21,482 - PPOAgent - INFO - Train: J_r=-37.0005, J_c=0.3806, Lambda=0.4494, Actor Loss=-1.7570, Critic Loss=10067.5693, Cost Critic Loss=0.0427, Entropy=-0.2843\n",
      "2025-11-03 23:29:21,482 - PPOAgent - INFO - Starting episode: 126\n",
      "2025-11-03 23:29:32,119 - PPOAgent - INFO - Train: J_r=-33.4120, J_c=0.4290, Lambda=0.4537, Actor Loss=0.6732, Critic Loss=9858.5879, Cost Critic Loss=0.0983, Entropy=-0.3068\n",
      "2025-11-03 23:29:32,119 - PPOAgent - INFO - Starting episode: 127\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    num_envs = config['n_envs']\n",
    "\n",
    "!python3 app/main_run_scenarios_parallel.py --scenarios-dir app/train_scenarios --n-envs $num_envs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
