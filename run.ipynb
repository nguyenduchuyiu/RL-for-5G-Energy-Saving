{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RL-for-5G-Energy-Saving'...\n"
     ]
    }
   ],
   "source": [
    "!git clone -b lagrangian-ppo --single-branch https://github.com/nguyenduchuyiu/RL-for-5G-Energy-Saving.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RL-for-5G-Energy-Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/dense_urban.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/dense_urban.json\n",
    "{\n",
    "  \"name\": \"Dense Urban\",\n",
    "  \"description\": \"3GPP Dense urban with macro and micro cells\",\n",
    "  \"deploymentScenario\": \"dense_urban\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"two_layer\",\n",
    "  \"isd\": 200,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"Uniform/macro\",\n",
    "  \"ueSpeed\": 3,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 10,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 1024,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 20,\n",
    "  \"peakHourMultiplier\": 1.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/urban_macro.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/urban_macro.json\n",
    "    {\n",
    "  \"name\": \"3GPP Urban Macro\",\n",
    "  \"description\": \"3GPP Urban macro deployment scenario with large cells and continuous coverage\",\n",
    "  \"deploymentScenario\": \"urban_macro\",\n",
    "  \n",
    "  \"carrierFrequency\": 2e9,\n",
    "  \"systemBandwidth\": 100e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 500,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 25,\n",
    "  \"cellRadius\": 200,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 30,\n",
    "  \"indoorRatio\": 0.8,\n",
    "  \"outdoorSpeed\": 30,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1000,\n",
    "  \"idlePower\": 250,\n",
    "  \n",
    "  \"simTime\": 1024,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -100,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 25,\n",
    "  \"peakHourMultiplier\": 1.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/high_speed.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/high_speed.json\n",
    "{\n",
    "  \"name\": \"High Speed\",\n",
    "  \"description\": \"3GPP High speed scenario for railway with linear deployment\",\n",
    "  \"deploymentScenario\": \"high_speed\",\n",
    "  \n",
    "  \"carrierFrequency\": 4e9,\n",
    "  \"systemBandwidth\": 200e6,\n",
    "  \"layout\": \"linear_railway\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 7,\n",
    "  \"numSectors\": 2,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 300,\n",
    "  \"userDistribution\": \"100% of users in train\",\n",
    "  \"ueSpeed\": 500,\n",
    "  \"indoorRatio\": 1.0,\n",
    "  \"trainLength\": 200,\n",
    "  \"trackLength\": 10000,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 1024,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -110,\n",
    "  \"rsrpTargetThreshold\": -95,\n",
    "  \"rsrpMeasurementThreshold\": -115,\n",
    "  \"dropCallThreshold\": 1,\n",
    "  \"latencyThreshold\": 50,\n",
    "  \"cpuThreshold\": 95,\n",
    "  \"prbThreshold\": 95,\n",
    "  \n",
    "  \"trafficLambda\": 30,\n",
    "  \"peakHourMultiplier\": 1.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/train_scenarios/rural.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/train_scenarios/rural.json\n",
    "{\n",
    "  \"name\": \"3GPP Rural Macro\",\n",
    "  \"description\": \"3GPP Rural deployment scenario with wide area coverage for high speed vehicles\",\n",
    "  \"deploymentScenario\": \"rural\",\n",
    "  \n",
    "  \"carrierFrequency\": 700e6,\n",
    "  \"systemBandwidth\": 20e6,\n",
    "  \"layout\": \"hexagonal_grid\",\n",
    "  \"isd\": 1732,\n",
    "  \n",
    "  \"numSites\": 19,\n",
    "  \"numSectors\": 3,\n",
    "  \"antennaHeight\": 35,\n",
    "  \"cellRadius\": 1000,\n",
    "  \n",
    "  \"numUEs\": 100,\n",
    "  \"userDistribution\": \"mixed_outdoor_indoor\",\n",
    "  \"ueSpeed\": 120,\n",
    "  \"indoorRatio\": 0.5,\n",
    "  \"outdoorSpeed\": 120,\n",
    "  \n",
    "  \"minTxPower\": 20,\n",
    "  \"maxTxPower\": 46,\n",
    "  \"basePower\": 1200,\n",
    "  \"idlePower\": 300,\n",
    "  \n",
    "  \"simTime\": 1024,\n",
    "  \"timeStep\": 1,\n",
    "  \n",
    "  \"rsrpServingThreshold\": -115,\n",
    "  \"rsrpTargetThreshold\": -105,\n",
    "  \"rsrpMeasurementThreshold\": -120,\n",
    "  \"dropCallThreshold\": 2,\n",
    "  \"latencyThreshold\": 100,\n",
    "  \"cpuThreshold\": 90,\n",
    "  \"prbThreshold\": 90,\n",
    "  \n",
    "  \"trafficLambda\": 10,\n",
    "  \"peakHourMultiplier\": 1.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "training_mode: True\n",
    "use_gpu: False\n",
    "\n",
    "checkpoint_load_path: \"models/0.pth\"\n",
    "checkpoint_save_path: \"models/final.pth\"\n",
    "\n",
    "actor_lr: 0.0001\n",
    "critic_lr: 0.0003\n",
    "\n",
    "energy_reward_scale: 0.005\n",
    "cost_scale: 2.0\n",
    "\n",
    "entropy_coef: 0.01\n",
    "gamma: 0.99\n",
    "lambda_gae: 0.95\n",
    "clip_epsilon: 0.2\n",
    "ppo_epochs: 4\n",
    "batch_size: 64\n",
    "buffer_size: 512\n",
    "n_envs: 4\n",
    "hidden_dim: 256\n",
    "\n",
    "# Lagrangian PPO settings\n",
    "lambda_init: 0.0\n",
    "lambda_lr: 0.1\n",
    "lambda_max: 10.0\n",
    "cost_target: 5.0\n",
    "cost_tolerance: 0.0\n",
    "cost_stop_patience: 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huy/anaconda3/envs/mira/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\n",
      "=== Running Benchmark Suite (4 scenarios) ===\n",
      "Scenarios directory: app/train_scenarios/\n",
      "Using 4 parallel environments per scenario\n",
      "Loaded scenarios: ['dense_urban', 'high_speed', 'rural', 'urban_macro']\n",
      "\n",
      "\n",
      "--- Scenario 1/4: dense_urban ---\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Loaded scenario: Dense Urban\n",
      "Created 4 parallel environments\n",
      "  Scenario: dense_urban\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: Dense Urban\n",
      "Skipping scenario dense_urban: simTime=0\n",
      "Loaded scenario: Dense Urban\n",
      "\n",
      "Results for dense_urban:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 2/4: high_speed ---\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Loaded scenario: High Speed\n",
      "Created 4 parallel environments\n",
      "  Scenario: high_speed\n",
      "  Action dim: 14\n",
      "  Obs dim: 196\n",
      "Loaded scenario: High Speed\n",
      "Skipping scenario high_speed: simTime=0\n",
      "Loaded scenario: High Speed\n",
      "\n",
      "Results for high_speed:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 3/4: rural ---\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: rural\n",
      "  Action dim: 57\n",
      "  Obs dim: 712\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "Skipping scenario rural: simTime=0\n",
      "Loaded scenario: 3GPP Rural Macro\n",
      "\n",
      "Results for rural:\n",
      "  Energy: 0.000000 kWh\n",
      "  Drop Rate: 0.00%\n",
      "  Latency: 0.0 ms\n",
      "  Handovers: 0 (Success: 0.0%)\n",
      "\n",
      "--- Scenario 4/4: urban_macro ---\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Created 4 parallel environments\n",
      "  Scenario: urban_macro\n",
      "  Action dim: 21\n",
      "  Obs dim: 280\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "Loaded scenario: 3GPP Urban Macro\n",
      "2025-11-10 22:50:03,246 - PPOAgent - INFO - PPO Agent initialized: 21 cells, 300 UEs\n",
      "2025-11-10 22:50:03,246 - PPOAgent - INFO - State dim: 817, Action dim: 100\n",
      "2025-11-10 22:50:03,246 - PPOAgent - INFO - Device: cpu\n",
      "2025-11-10 22:50:03,246 - PPOAgent - INFO - No checkpoint found at models/0.pth\n",
      "Created 7 sites for urban_macro scenarioCreated 7 sites for urban_macro scenario\n",
      "\n",
      "Configuring cells for urban_macro scenario...Configuring cells for urban_macro scenario...\n",
      "\n",
      "Configured 21 cells for urban_macro scenarioConfigured 21 cells for urban_macro scenario\n",
      "\n",
      "Created 7 sites for urban_macro scenario\n",
      "Configuring cells for urban_macro scenario...\n",
      "Configured 21 cells for urban_macro scenario\n",
      "Created 7 sites for urban_macro scenario\n",
      "Configuring cells for urban_macro scenario...\n",
      "Configured 21 cells for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "Initialized 300 UEs for urban_macro scenario\n",
      "===================Starting scenario===================\n",
      "2025-11-10 22:50:14,675 - PPOAgent - INFO - Starting episode: 1\n",
      "Training with 4 parallel environments...\n",
      "Total steps: 4096\n",
      "Energy=21259.6094, Total Traffic Demand=0.0000, Reward=0.0000\n",
      "2025-11-10 22:50:27,242 - PPOAgent - INFO - Train: J_r=0.0000, J_c=1.4217, Target+tol=1.2000, Streak=0/10, Lambda=0.0222, Actor Loss=0.9517, Critic Loss=0.0004, Cost Critic Loss=0.2240, Entropy=19.3193\n",
      "2025-11-10 22:50:27,242 - PPOAgent - INFO - Starting episode: 2\n",
      "Energy=25820.8535, Total Traffic Demand=0.0000, Reward=0.0000\n",
      "2025-11-10 22:50:39,241 - PPOAgent - INFO - Train: J_r=0.0000, J_c=3.0894, Target+tol=1.2000, Streak=0/10, Lambda=0.2111, Actor Loss=-0.3361, Critic Loss=0.0060, Cost Critic Loss=0.1848, Entropy=19.3738\n",
      "2025-11-10 22:50:39,241 - PPOAgent - INFO - Starting episode: 3\n",
      "Energy=25630.8730, Total Traffic Demand=47.0000, Reward=-2.7267\n",
      "2025-11-10 22:50:51,108 - PPOAgent - INFO - Train: J_r=-2.7076, J_c=2.6145, Target+tol=1.2000, Streak=0/10, Lambda=0.3526, Actor Loss=-1.6935, Critic Loss=0.0460, Cost Critic Loss=10.5665, Entropy=19.3910\n",
      "2025-11-10 22:50:51,108 - PPOAgent - INFO - Starting episode: 4\n",
      "Energy=25698.7246, Total Traffic Demand=32.0000, Reward=-4.0154\n",
      "2025-11-10 22:51:02,615 - PPOAgent - INFO - Train: J_r=-3.5055, J_c=3.3303, Target+tol=1.2000, Streak=0/10, Lambda=0.5656, Actor Loss=-0.2578, Critic Loss=1.8763, Cost Critic Loss=0.3381, Entropy=19.5300\n",
      "2025-11-10 22:51:02,616 - PPOAgent - INFO - Starting episode: 5\n",
      "Energy=25627.4551, Total Traffic Demand=43.0000, Reward=-2.9799\n",
      "2025-11-10 22:51:14,317 - PPOAgent - INFO - Train: J_r=-2.7014, J_c=2.0812, Target+tol=1.2000, Streak=0/10, Lambda=0.6537, Actor Loss=0.9261, Critic Loss=2.1305, Cost Critic Loss=2.6796, Entropy=19.5070\n",
      "2025-11-10 22:51:14,317 - PPOAgent - INFO - Starting episode: 6\n",
      "Energy=25708.4004, Total Traffic Demand=41.0000, Reward=-3.1352\n",
      "2025-11-10 22:51:25,451 - PPOAgent - INFO - Train: J_r=-3.5412, J_c=4.8279, Target+tol=1.2000, Streak=0/10, Lambda=1.0165, Actor Loss=-2.5167, Critic Loss=8.0936, Cost Critic Loss=20.2524, Entropy=19.3536\n",
      "2025-11-10 22:51:25,451 - PPOAgent - INFO - Starting episode: 7\n",
      "Energy=25779.1074, Total Traffic Demand=44.0000, Reward=-2.9294\n",
      "2025-11-10 22:51:37,035 - PPOAgent - INFO - Train: J_r=-3.0345, J_c=2.9965, Target+tol=1.2000, Streak=0/10, Lambda=1.1962, Actor Loss=-0.0329, Critic Loss=0.0239, Cost Critic Loss=0.4070, Entropy=20.4294\n",
      "2025-11-10 22:51:37,035 - PPOAgent - INFO - Starting episode: 8\n",
      "Energy=25628.4375, Total Traffic Demand=50.0000, Reward=-2.5628\n",
      "2025-11-10 22:51:48,743 - PPOAgent - INFO - Train: J_r=-3.0453, J_c=1.8782, Target+tol=1.2000, Streak=0/10, Lambda=1.2640, Actor Loss=-1.3637, Critic Loss=5.3561, Cost Critic Loss=1.5221, Entropy=21.2636\n",
      "2025-11-10 22:51:48,744 - PPOAgent - INFO - Starting episode: 9\n",
      "Energy=25641.6230, Total Traffic Demand=36.0000, Reward=-3.5613\n",
      "2025-11-10 22:52:00,347 - PPOAgent - INFO - Train: J_r=-3.1767, J_c=3.0455, Target+tol=1.2000, Streak=0/10, Lambda=1.4485, Actor Loss=-1.4738, Critic Loss=1.1125, Cost Critic Loss=12.4183, Entropy=21.0807\n",
      "2025-11-10 22:52:00,348 - PPOAgent - INFO - Starting episode: 10\n",
      "Energy=25700.7910, Total Traffic Demand=44.0000, Reward=-2.9205\n",
      "2025-11-10 22:52:11,902 - PPOAgent - INFO - Train: J_r=-3.0965, J_c=3.7812, Target+tol=1.2000, Streak=0/10, Lambda=1.7066, Actor Loss=-0.4307, Critic Loss=1.0752, Cost Critic Loss=13.4020, Entropy=21.0008\n",
      "2025-11-10 22:52:11,903 - PPOAgent - INFO - Starting episode: 11\n",
      "Energy=25667.1406, Total Traffic Demand=48.0000, Reward=-2.6737\n",
      "2025-11-10 22:52:23,416 - PPOAgent - INFO - Train: J_r=-2.9390, J_c=3.7422, Target+tol=1.2000, Streak=0/10, Lambda=1.9609, Actor Loss=-0.5585, Critic Loss=0.1781, Cost Critic Loss=10.0753, Entropy=20.3714\n",
      "2025-11-10 22:52:23,416 - PPOAgent - INFO - Starting episode: 12\n",
      "Energy=25711.3535, Total Traffic Demand=42.0000, Reward=-3.0609\n",
      "2025-11-10 22:52:35,075 - PPOAgent - INFO - Train: J_r=-3.3026, J_c=2.1034, Target+tol=1.2000, Streak=0/10, Lambda=2.0512, Actor Loss=-0.1166, Critic Loss=3.5435, Cost Critic Loss=1.1137, Entropy=20.1942\n",
      "2025-11-10 22:52:35,075 - PPOAgent - INFO - Starting episode: 13\n",
      "Energy=25471.1270, Total Traffic Demand=33.0000, Reward=-3.8593\n",
      "2025-11-10 22:52:46,522 - PPOAgent - INFO - Train: J_r=-3.2078, J_c=3.4375, Target+tol=1.2000, Streak=0/10, Lambda=2.2750, Actor Loss=1.4567, Critic Loss=0.5604, Cost Critic Loss=4.7233, Entropy=20.1440\n",
      "2025-11-10 22:52:46,522 - PPOAgent - INFO - Starting episode: 14\n",
      "Energy=25605.5508, Total Traffic Demand=32.0000, Reward=-4.0009\n",
      "2025-11-10 22:52:58,104 - PPOAgent - INFO - Train: J_r=-3.3117, J_c=2.7844, Target+tol=1.2000, Streak=0/10, Lambda=2.4334, Actor Loss=-2.8223, Critic Loss=9.1217, Cost Critic Loss=1.2719, Entropy=19.5278\n",
      "2025-11-10 22:52:58,104 - PPOAgent - INFO - Starting episode: 15\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 253, in <module>\n",
      "    main(n_parallel_envs=args.n_envs, scenarios_dir=args.scenarios_dir)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 67, in main\n",
      "    results = run_scenario_with_rl_agent_parallel(\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/main_run_scenarios_parallel.py\", line 182, in run_scenario_with_rl_agent_parallel\n",
      "    next_obs, rewards, new_dones, infos = envs.step(actions)\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in step\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/Project/public_1/5GEnergySaving-Round1-public/app/simple_parallel_env.py\", line 127, in <listcomp>\n",
      "    results = [conn.recv() for conn in self.parent_conns]\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/huy/anaconda3/envs/mira/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    num_envs = config['n_envs']\n",
    "\n",
    "!python3 app/main_run_scenarios_parallel.py --scenarios-dir app/train_scenarios --n-envs $num_envs"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
